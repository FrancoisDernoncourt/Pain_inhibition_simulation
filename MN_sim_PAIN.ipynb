{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, windows\n",
    "from scipy.stats import linregress\n",
    "%matplotlib inline\n",
    "import scipy.io\n",
    "from scipy.signal import resample, freqz\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import remez, firwin, lfilter\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import csd, detrend\n",
    "import pickle\n",
    "from scipy.fft import fft, fftfreq\n",
    "import sys\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS ###\n",
    "start_scope() # Re-initialize Brian\n",
    "plt.style.use('_classic_test_patch') # Plotting style\n",
    "\n",
    "### GENERAL PARAMETERS ###########################################################\n",
    "sim_name = 'PAIN_sim_testing_no_inhib' #'PAIN_sim_100percent_exponential_distrib_inhib_test'\n",
    "\n",
    "# TIME PARAMETERS\n",
    "fsamp = 1000  # set your fsamp # This is NOT the dt at which the simulation runs. The simulation timesteps are 0.1ms in duration by default\n",
    "window_beginning_ignore = 1 # in s\n",
    "window_end_ignore = 1 # in s\n",
    "ISI_threshold_for_discontinuity = 0.4 # in s ; motoneurons whose max(ISI)>threshold will be removed from analysis (so only continuous MNs are kept)\n",
    "\n",
    "# VOLTAGE THRESHOLDS OF ALL NEURONS\n",
    "voltage_rest = 0 # arbitrary ; 0 at rest\n",
    "voltage_thresh = 1 # arbitrary ; 1 for generating a spike\n",
    "\n",
    "# NUMBER OF NEURONS SIMULATED\n",
    "nb_motoneurons_full_pool = 300 # All motoneurons from the pool to be simulated\n",
    "\n",
    "# SIMULATING THE HD-EMG MU IDENTIFICATION PROCESS BY SUB-SAMPLING THE ACTIVE MUs\n",
    "subsample_MUs_for_analysis = False # True\n",
    "nb_of_MUs_to_subsample = 50\n",
    "motor_unit_subsampling_probability_distribution = 'size' # 'size' #'uniform', 'size' # if 'uniform\", every active MU will have the same probability to be selected for the analysis; if 'size\", larger motor units will have a higher probability of being selected\n",
    "bias_towards_larger_motor_neurons_temperature = 5.0 # only used if motor_unit_subsampling_probability_distribution=='size'.\n",
    "# If infinity (inf), same as uniform distribution. If ~100, probability is approximately linearly scaled according to size. Exponential bias for values below (very strong bias for temperature = 1 for example). Error if 0\n",
    "\n",
    "\n",
    "### TARGET SIMULATION\n",
    "target_type = 'trapezoid' #'sinusoid' # 'plateau' #'trapezoid'\n",
    "target_force_level = 30 # % of the max tetanic force of the simulated MNs\n",
    "# if trapezoid:\n",
    "ramp_duration = 6 # in s\n",
    "plateau_duration = 60 # 60 # 20 # in s\n",
    "analyzis_window = 'plateau'# 'all' 'plateau' # if 'all', the entire signal will be analyzed. If 'plateau', only the plateau section will be analyzed.\n",
    "# if sinusoid:\n",
    "target_force_sin_freq = 1 # used only if targt_type == 'sinusoid'\n",
    "\n",
    "### SIMULATION DURATION\n",
    "if target_type != 'trapezoid':\n",
    "    true_duration = 20\n",
    "else:\n",
    "    true_duration = ramp_duration*2 + plateau_duration\n",
    "duration_with_ignored_window = (true_duration+window_beginning_ignore+window_end_ignore)*second\n",
    "\n",
    "\n",
    "### INPUT PARAMETERS #########################################################\n",
    "\n",
    "# INHIBITORY INPUT\n",
    "inhibition_distribution = 'homogeneous' # 'heterogeneous', 'homogeneous'\n",
    "# 'heterogeneous' = Distribution randomly distributed to increasing X% of motor neurons\n",
    "# 'homogeneous' = Identical distribution of inhibition to all motor neurons (equivalent to 'heterogeneous' with 'proportion_of_MN_affected_by_each_inhibitory_input = 100')\n",
    "inhibition_weight_distribution = 'uniform' #'uniform\" 'exponential'\n",
    "# 'exponential' = MNs receiving inhibition will receive increasing or decreasing amount of inhibition according to their sizes - Martinez Valdes J physiol 2020 model = https://physoc.onlinelibrary.wiley.com/doi/full/10.1113/JP279225 \n",
    "# 'uniform' = all MNs receiving inhibition will receive the same amount of inhibition (identical to 'exponential' with 'inhibition_exponent_weights = 0')\n",
    "inhibition_exponent_weights_original = 20 # very high but allows to get a meaningful difference in the simulated and active MNs # used only if 'inhibition_weight_distribution = exponential'\n",
    "inhibition_constant_weights_original = 1 # used only if 'inhibition_weight_distribution = exponential'\n",
    "inhibition_offset_weights_original = 0\n",
    "# Distribution of inhibitory weights = constant * MN_size^(exponent) + offset\n",
    "proportion_of_MN_affected_by_each_inhibitory_input_original = 100 # 44 # in % (used only if 'inhibition_distribution = heterogeneous')\n",
    "# ^ given the current parameters, the mean of the weights for the distribution of inhibitory input is ~44% when the distribution is exponential and the proportion of MN affected = 100 (when sampling all continuous motor units), so using 44 when distributing inhibition randomly among motor units\n",
    "nb_inhibitory_input = 0\n",
    "low_pass_filter_of_inhibitory_input = 5 #in hz\n",
    "inhibitory_input_mean = -0.5 #-0.5 #-0.1 -0.05 # if inhib_before_force_optimization = False, inhibitory_input_mean should be close to 0 (otherwise very few MUs will fire and the force will be low)\n",
    "# use -0.5 if inhib_before_force_optimization = True; use -0.05 if inhib_before_force_optimization = False\n",
    "inhibitory_input_std = 0.025\n",
    "prevent_inhibition_from_being_positive = True # If the inhibition is noisy (std != 0), this makes sure that the inhiitory input will alway be < 0 (inhibitory)\n",
    "# Determine in which the inhibition will happen in the script\n",
    "inhib_before_force_optimization = True # True # False # If True, the force will be optimized taking the inhibitory input into account, so the common excitatory input will necessarily increase\n",
    "# If false, the inhibitory input will be delivered after the common excitatory input has been optimized to reach the target force. So the force level will be reduced, but the common excitatory input will remain the same as when there is no inhibition.\n",
    "\n",
    "inhibitory_input_source = 'generate_synthetic_input' # 'generate_synthetic_input' ; 'load_synthetic_input'\n",
    "inhibitory_input_sourcefile = 'D:/THESE/Git_Scripts/Python_Scripts/motoneuron_simulation/Synthetic_signals.csv' # used only if inhibitory_input_source == 'load_synthetic_input'\n",
    "# use the N first signals (the first N columns) as inhibitory inputs, with N = nb_inhibitory_input\n",
    "# Use a .csv file. The number of samples in the csv file should be >= the number of samples in the simulation\n",
    "inhibitory_input_sourcefile_fsamp = 1000 # 1000 if .csv ; 2048 if .mat # If not matching the simulation's fsamp, the loaded signal will be upsampled or downsampled to match the simulation's sampling rate\n",
    "\n",
    "\n",
    "# COMMON EXCITATORY INPUT\n",
    "common_input_baseline = voltage_thresh + 1.5\n",
    "common_input_fluctuations_amplitude = 0.025 # 0.025 # Added to the \"baseline common input\" learned by optimization (reducing error between force produced and target force)\n",
    "low_pass_filter_of_common_noise = 5 # in hz\n",
    "\n",
    "common_input_source = 'generate_synthetic_input' # 'generate_synthetic_input' ; 'load_synthetic_input' ; 'load_experimental_data'\n",
    "common_input_sourcefile = 'D:/THESE/Git_Scripts/Python_Scripts/motoneuron_simulation/Synthetic_signals.csv' # used only if common_input_source == 'load_synthetic_input' or 'load_experimental_data'\n",
    "# Use the last signal (last column) as common noise\n",
    "# If 'load_gaussian_noise', use a .csv file. The number of samples in the csv file should be >= the number of samples in the simulation\n",
    "# If 'load_experimental_data', use one .mat file or several .mat files. If several .mat files are selected, they will be concatenated. The number of samples in the (concatenated) file(s) should be >= the number of samples in the simulation\n",
    "common_input_sourcefile_fsamp = 1000 # 1000 if .csv ; 2048 if .mat # If not matching the simulation's fsamp, the loaded signal will be upsampled or downsampled to match the simulation's sampling rate\n",
    "\n",
    "# INDEPENDENT NOISE\n",
    "low_pass_filter_of_independent_noise = 50 # in hz\n",
    "independent_noise_amplitude = 0.05 # common_input_fluctuations_amplitude * 2 # the value of noise in std (mean of 0)\n",
    "\n",
    "\n",
    "### MOTONEURON PROPERTIES ACCORDING TO THEIR SIZES ##########################\n",
    "\n",
    "# Electrophysiological properties calculated from Caillet et al 2022 https://elifesciences.org/articles/76489\n",
    "# Assuming that soma diameter from human motoneurons vary between 50 and 100 micrometers, based on https://journals.physiology.org/doi/full/10.1152/physiol.00021.2018\n",
    "    # ^ \"Scaling of motoneurons, From Mouse to Human\" Manuel et al. Physiology (2018)\n",
    "min_soma_diameter = 50 # in micrometers, for smallest MN\n",
    "max_soma_diameter = 100 # in micrometers, for largest MN\n",
    "# Select the range of MNs simulates (0 being smallest, 100 being largest)\n",
    "min_normalized_boundary = 0 #0 # Normalized between 0 and 100\n",
    "max_normalized_boundary = 100 # Normalized between 0 and 100 - use a value below 100 if not simulating very fast MNs #20 to go up to 20% MVC\n",
    "\n",
    "# DISTRIBUTION OF MOTONEURON SIZES\n",
    "# Parameter to create an exponetially decreasing dsitribution curve, with larger motoneurons being less numerous than smaller motoneurons\n",
    "# Somewhat fitting the curve in Principles of Neural Science 2021 edition, Enoka chapter on motor units, fig 31-3.A\n",
    "size_distribution_exponent = 2\n",
    "# size_distribution_exponent between 0.8 and 0.9 results in a quasi-uniform distribution of MN sizes\n",
    "\n",
    "#### ELECTROPHYSIOLOGICAL MN PROPERTIES #####\n",
    "tau_constant = 2.6*(10**4) # Caillet et al 2022\n",
    "tau_exponent = 1.5 # Caillet et al 2022\n",
    "    # https://www.desmos.com/calculator/bfhcpgiltr = visualize the curve\n",
    "    # Min time constant for smallest MN (50 micrometers) = ~26ms\n",
    "    # Max time constant for biggest MN (100 micrometers) = ~70ms\n",
    "    # From Williams & Baker 2009 = \"These decay times correspond with exponential time constants of 24 –26 ms, in keeping with previous models of motoneurons (Matthews, 1997)\"\n",
    "    # From Vertebrate Motoneurons 2022:\n",
    "        # 3-15ms in cat ; 2-20ms in mouse\n",
    "        # \"Consequently, several labs use the half-decay time of AHP to distinguish between F-fast and S-slow rat motoneurons (F > 20 ms, S < 20 ms, (Gardiner 1993)) but the difference between the FR and FF motoneurons is not well defned.\"\n",
    "    # From \"Principles of Neural Science\":\n",
    "        # \"Typical values of τ for neurons range from 20 to 50ms\" (but not motor neurons specifically)\n",
    "    # From the same book: \"Cell membrane time constant; the product of resistance and capacitance of the membrane (typical values 1–20 ms). tau = Rm ⋅ Cm\"\n",
    "    # Maltenfort, Heckman 1998 simulation study = 2.5-10ms time constant for motoneurons\n",
    "#### Refractory period, linear relationship (Caillet's paper gives equations for AHP duration but not for refractory period duration) #####\n",
    "refractory_period_smallest_MN = 20*ms\n",
    "refractory_period_largest_MN = 5*ms\n",
    "    # Manuel et al. 2019 \"Scaling of motor output, from Mouse to Humans\"\n",
    "        # \"Statistical methods employed at low firing rates indicate the AHP durations of low-threshold human motoneurons, presumably type S and perhaps some type FR, are ~125–140 ms.\"\n",
    "    # Herbert & Gandevia 1999 assume a 5ms (absolute?) refractory period\n",
    "    # Lateva et at 2001 = Absolute refractory period of 3ms in muscle fibers, and relative refractory period of 10ms\n",
    "    # University of Washington textbook of physiology = in a typical neuron, the absolute refractory period lasts a few ms and the relative period tens of ms\n",
    "    # Tuned to avoid unrealistically high discharge rates when computing the MVC => 20ms maxes out the discharge rate of small MNs at 50pps\n",
    "#### Input weight = normalizd resistance, so that the input to the smallest MN is scaled by a factor of 0 #####\n",
    "resistance_constant = 9.6*(10**5) # Caillet et al 2022\n",
    "resistance_exponent = 2.4 # Caillet et al 2022\n",
    "    # https://www.desmos.com/calculator/pbs97zynff = visualize the curve for resistance (ohms) and input weights (between 0 and 1)\n",
    "    # Min input weight for smallest MN (50 micrometers) = 1\n",
    "    # Max input weight for biggest MN (100 micrometers) = ~0.19\n",
    "\n",
    "### CONTRACTILE PROPERTIES (TWITCH FORCE CAUSED BY MN SPIKES)\n",
    "    # Every firing of motor units will be convolved with a kernel\n",
    "    #  => The kernel is a hanning window of duration which is 2x the time to peak force, and then the duration of the \"down\" portion of the twitch (when the force returns to baseline) is extended by 'multiplication_of_twitch_force_down_time'\n",
    "    #   # Finally, the conduction delay is added before the start of the kernel\n",
    "    # Linear interpolation to get force produced (this is a gross simplification, as the distribution of MU properties is not linearly distributed at all)\n",
    "    # Data from Principles of Neural Science 2021 edition Motor Unit chapter Enoka # Figure 31-3, values for human tibialis anterior motor units => between 0-10 mN/m for smallest MUs, ~140mN/m for largest MUs\n",
    "# Value in twitch torque (milliNewton/m)\n",
    "twitch_force_range_small_MU = 5 # in milliNewton/meter\n",
    "twitch_force_range_large_MU = 140 # in milliNewton/meter\n",
    "    # The twitch force values are later normalized according to % of MVC, with the MVC being calculated as the force produces when all simulatd motor units receive extremely strong excitatory input\n",
    "# twitch duration (Duration of the Gaussian kernel) => linear relationship (this is a gross simplification, as the distribution of MU properties is not linearly distributed at all)\n",
    "    # ~20ms to peak force for fastest motor units ; ~80ms to peak force for slowest motor units - Principles of Neural Science 2021 edition Motor Unit chapter Enoka # Figure 31-3, values for human tibialis anterior motor units\n",
    "    # Doubling the value because this is time to peak force, and kernel duration is twice that\n",
    "    #    # Also some data from Shoepe et al 2003 MSSE, shortening velocity of type I fiber (twitch_duration small MU = 120ms, time to peak force = 60ms) VS type IIa fiber (twitch duration fast MU = 50ms, time to peak force = 25ms)\n",
    "    #    # https://paulogentil.com/pdf/Functional%20adaptability%20of%20muscle%20fibers%20to%20long-term%20resistance%20exercise.pdf\n",
    "time_to_peak_twitch_force_range_small_MU = 0.16 # in s\n",
    "time_to_peak_twitch_force_range_large_MU = 0.04 # in s # biggest MU\n",
    "multiplication_of_twitch_force_down_time = 4 # This is a gross simplificaion of how the twitch force return to baseline, but overall it seems to fit the behavior of motor units\n",
    "    # B. R. Botterman, G. A. Iwamoto, and W. J. Gonyea (1986) = force trace of single twitchs from motor units\n",
    "    # Rositsa Raikova, Piotr Krutki, Jan Celichowski (2023) => Detailed model of motor units twitch force\n",
    "# Electromechanical delay => inverse of actional conduction velocity\n",
    "axonal_conduction_velocity_constant = 4.0*2 # Inferred from the axonal conduction velocity relationship reported in Caillet et al 2022,\n",
    "# ^ multiplying by two (assuming a 0.5m axon length => so correspond to the conduction speed from MN to muscle fiber)\n",
    "axonal_conduction_velocity_exponent = 0.7 # Caillet et al 2022\n",
    "low_pass_filter_force = False # Can be turned to true if fast oscillation (high frequency components) in force output\n",
    "low_pass_filter_of_force_cutoff = 5 # in hz\n",
    "\n",
    "### PARAMETERS FOR TESTING - reduce numbers for faster simulations\n",
    "COH_calc_max_iteration_nb_per_group_size = 1000 # 10 for faster simulation\n",
    "# More iteration for smaller group sizes, because the value obtained is very dependent upon the exact neurons selected, especially when only a few MNs are used to create the CST\n",
    "# ^ the number of iteration will be \"COH_calc_max_iteration_nb_per_group_size / nb_of_MUs_in_CST\"\n",
    "num_optimization_iterations = 10 # 5 for faster simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE PARAMETERS\n",
    "new_directory = sim_name\n",
    "new_filename = 'parameters.txt'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(new_directory):\n",
    "    os.makedirs(new_directory)\n",
    "else:\n",
    "    directory_n = 0\n",
    "    while os.path.exists(new_directory):\n",
    "        directory_n = directory_n+1\n",
    "        new_directory = str(sim_name + \"_iter_\" + str(directory_n))\n",
    "        if not os.path.exists(new_directory):\n",
    "            os.makedirs(new_directory)\n",
    "            break\n",
    "        if directory_n > 99: # prevent infinite loop\n",
    "            break\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "\n",
    "# Write the variables to the file\n",
    "with open(save_file_path, 'w') as file:\n",
    "    file.write(f\"General parameters -----\\n\")\n",
    "    file.write(f\"   duration_with_ignored_window: {duration_with_ignored_window}\\n\")\n",
    "    file.write(f\"   nb_motoneurons_full_pool_per_pool: {nb_motoneurons_full_pool}\\n\")\n",
    "    file.write(f\"Sub-sampling of motor units (simulating the hdEMG motor unit identification process) -----\\n\")\n",
    "    file.write(f\"   subsample_MUs_for_analysis: {subsample_MUs_for_analysis}\\n\")\n",
    "    file.write(f\"   nb_of_MUs_to_subsample: {nb_of_MUs_to_subsample}\\n\")\n",
    "    file.write(f\"   motor_unit_subsampling_probability_distribution: {motor_unit_subsampling_probability_distribution}\\n\")\n",
    "    file.write(f\"   bias_towards_larger_motor_neurons_temperature: {bias_towards_larger_motor_neurons_temperature}\\n\")\n",
    "\n",
    "    file.write(f\"\\n\")\n",
    "    file.write(f\"Input parameters -----\\n\")\n",
    "    file.write(f\"   Common exitatory input -----\\n\")\n",
    "    file.write(f\"       common_input_baseline (before optimized input learning): {common_input_baseline}\\n\")\n",
    "    file.write(f\"       common_input_fluctuations_amplitude: {common_input_fluctuations_amplitude }\\n\")\n",
    "    file.write(f\"       common_input_source: {common_input_source }\\n\")\n",
    "    file.write(f\"       common_input_sourcefile: {common_input_sourcefile }\\n\")\n",
    "    file.write(f\"       common_input_sourcefile_fsamp: {common_input_sourcefile_fsamp }\\n\")\n",
    "    file.write(f\"   Independent input (noise) -----\\n\")\n",
    "    file.write(f\"       low_pass_filter_of_independent_noise: {low_pass_filter_of_independent_noise}\\n\")\n",
    "    file.write(f\"       independent_noise_amplitude: {independent_noise_amplitude}\\n\")\n",
    "    file.write(f\"   Inhibitory input (noise) -----\\n\")\n",
    "    file.write(f\"       inhibition_distribution: {inhibition_distribution}\\n\")\n",
    "    file.write(f\"       inhibition_weight_distribution: {inhibition_weight_distribution}\\n\")\n",
    "    file.write(f\"        - If exponential distribution of inhibitory input:\\n\")\n",
    "    file.write(f\"           inhibition_exponent_weights_original: {inhibition_exponent_weights_original}\\n\")\n",
    "    file.write(f\"           inhibition_constant_weights_original: {inhibition_constant_weights_original}\\n\")\n",
    "    file.write(f\"           inhibition_offset_weights_original: {inhibition_offset_weights_original}\\n\")\n",
    "    file.write(f\"        - If heterogeneous weight distribution of inhibitory input:\\n\")\n",
    "    file.write(f\"           proportion_of_MN_affected_by_each_inhibitory_input_original: {proportion_of_MN_affected_by_each_inhibitory_input_original}\\n\")\n",
    "    file.write(f\"       nb_inhibitory_input: {nb_inhibitory_input}\\n\")\n",
    "    file.write(f\"       low_pass_filter_of_inhibitory_input: {low_pass_filter_of_inhibitory_input}\\n\")\n",
    "    file.write(f\"       inhibitory_input_mean: {inhibitory_input_mean}\\n\")\n",
    "    file.write(f\"       inhibitory_input_std: {inhibitory_input_std}\\n\")\n",
    "    file.write(f\"       prevent_inhibition_from_being_positive: {prevent_inhibition_from_being_positive}\\n\")\n",
    "    file.write(f\"       inhibitory_input_source: {inhibitory_input_source}\\n\")\n",
    "    file.write(f\"       inhibitory_input_sourcefile: {inhibitory_input_sourcefile}\\n\")\n",
    "    file.write(f\"       inhibitory_input_sourcefile_fsamp: {inhibitory_input_sourcefile_fsamp}\\n\")\n",
    "\n",
    "    file.write(f\"\\n\")\n",
    "    file.write(f\"Force target parameters -----\\n\")\n",
    "    file.write(f\"   target_type: {target_type}\\n\")\n",
    "    file.write(f\"   target_force_level: {target_force_level}% MVC\\n\")\n",
    "    file.write(f\"   If trapezoid:\\n\")\n",
    "    file.write(f\"       ramp_duration: {ramp_duration}\\n\")\n",
    "    file.write(f\"       plateau_duration: {plateau_duration}\\n\")\n",
    "    file.write(f\"   If NOT trapezoid:\\n\")\n",
    "    file.write(f\"       true_duration: {true_duration}\\n\")\n",
    "    file.write(f\"   If sisnusoid:\\n\")\n",
    "    file.write(f\"       target_force_sin_freq (used only if targt_type == 'sinusoid'): {target_force_sin_freq}\\n\")\n",
    "    file.write(f\"   low_pass_filter_force: {low_pass_filter_force}\\n\")\n",
    "    file.write(f\"   low_pass_filter_of_force_cutoff: {low_pass_filter_of_force_cutoff}\\n\")\n",
    "\n",
    "    file.write(f\"Motor neurons size -----\\n\")\n",
    "    file.write(f\"   min_soma_diameter: {min_soma_diameter}\\n\")\n",
    "    file.write(f\"   max_soma_diameter: {max_soma_diameter}\\n\")\n",
    "    file.write(f\"   min_normalized_boundary : {min_normalized_boundary}\\n\")\n",
    "    file.write(f\"   max_normalized_boundary : {max_normalized_boundary}\\n\")\n",
    "    file.write(f\"   size_distribution_exponent : {size_distribution_exponent}\\n\")\n",
    "\n",
    "    file.write(f\"\\n\")\n",
    "    file.write(f\"Twitch force properties - parameters -----\\n\")\n",
    "    file.write(f\"   twitch_force_range_small_MU: {twitch_force_range_small_MU}\\n\")\n",
    "    file.write(f\"   twitch_force_range_large_MU: {twitch_force_range_large_MU}\\n\")\n",
    "    file.write(f\"   time_to_peak_twitch_force_range_small_MU: {time_to_peak_twitch_force_range_small_MU}\\n\")\n",
    "    file.write(f\"   time_to_peak_twitch_force_range_large_MU: {time_to_peak_twitch_force_range_large_MU}\\n\")\n",
    "    file.write(f\"   multiplication_of_twitch_force_down_time: {multiplication_of_twitch_force_down_time}\\n\")\n",
    "    file.write(f\"   axonal_conduction_velocity_constant: {axonal_conduction_velocity_constant}\\n\")\n",
    "    file.write(f\"   axonal_conduction_velocity_exponent: {axonal_conduction_velocity_exponent}\\n\")\n",
    "\n",
    "    file.write(f\"\\n\")\n",
    "    file.write(f\"Electrophysiological properties - parameters -----\\n\")\n",
    "    file.write(f\"   twitch_force_range_small_MU: {twitch_force_range_small_MU}\\n\")\n",
    "    file.write(f\"   twitch_force_range_large_MU: {twitch_force_range_large_MU}\\n\")\n",
    "    file.write(f\"   time_to_peak_twitch_force_range_small_MU: {time_to_peak_twitch_force_range_small_MU}\\n\")\n",
    "    file.write(f\"   time_to_peak_twitch_force_range_large_MU: {time_to_peak_twitch_force_range_large_MU}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lerp (linear interpolation) function:\n",
    "def lerp(a, b, t):\n",
    "    return a + t * (b - a)\n",
    "\n",
    "####### Generate motoneurons and their properties\n",
    "motoneuron_normalized_soma_diameters = linspace(min_normalized_boundary,max_normalized_boundary,nb_motoneurons_full_pool)/(max_normalized_boundary-min_normalized_boundary) # = uniform distribution\n",
    "\n",
    "# size_distribution_constant = 1\n",
    "# size_distribution_exponent = 1/2\n",
    "# size_distribution_offset = 0\n",
    "# for mni in range(nb_motoneurons_full_pool):\n",
    "#     motoneuron_normalized_soma_diameters[mni] = (size_distribution_constant * (lerp(0,1,motoneuron_normalized_soma_diameters[mni])**size_distribution_exponent)) + size_distribution_offset\n",
    "#     motoneuron_normalized_soma_diameters[mni] = max(0, min(motoneuron_normalized_soma_diameters[mni], 1)) # clamp between 0 and 1\n",
    "#     motoneuron_normalized_soma_diameters[mni] = abs(motoneuron_normalized_soma_diameters[mni] - 1)\n",
    "# motoneuron_normalized_soma_diameters = motoneuron_normalized_soma_diameters[::-1] # flipping vector so that idx 0 is the smallest MN\n",
    "\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    motoneuron_normalized_soma_diameters[mni] = 0.581976 * (np.exp(motoneuron_normalized_soma_diameters[mni]**size_distribution_exponent)-1)\n",
    "# The first number ensures that the result starts at 0\n",
    "\n",
    "motoneuron_soma_diameters = np.zeros(nb_motoneurons_full_pool)\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    motoneuron_soma_diameters[mni] = lerp(min_soma_diameter, max_soma_diameter, motoneuron_normalized_soma_diameters[mni])\n",
    "\n",
    "# Plot histogram of motoneuron sizes\n",
    "plt.figure()\n",
    "# Create the histogram\n",
    "counts, bins, patches = plt.hist(motoneuron_soma_diameters, density=True)\n",
    "# Multiply the counts by 100 to convert to percentage\n",
    "counts_percentage = counts * 100\n",
    "# Plot the histogram again with the adjusted counts\n",
    "plt.clf()  # Clear the current plot\n",
    "plt.hist(motoneuron_soma_diameters, density=False, weights=np.ones_like(motoneuron_soma_diameters) * (100 / len(motoneuron_soma_diameters)),\n",
    "         edgecolor='white', alpha=0.75)\n",
    "plt.vlines(min_soma_diameter,plt.ylim()[0],plt.ylim()[1],color='C1', label='Min soma diameter', linewidth=2)\n",
    "plt.vlines(max_soma_diameter,plt.ylim()[0],plt.ylim()[1],color='C3', label='Max soma diameter', linewidth=2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Motoneuron size (soma diameter in micrometer)\")\n",
    "plt.ylabel(\"Proportion (% of total nb of motoneurons)\")\n",
    "plt.title(\"Distribution of motor neuron sizes\")\n",
    "new_filename = f'MN_sizes_distribution.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "# Create the histogram\n",
    "counts, bins, patches = plt.hist(motoneuron_normalized_soma_diameters, density=True)\n",
    "# Multiply the counts by 100 to convert to percentage\n",
    "counts_percentage = counts * 100\n",
    "# Plot the histogram again with the adjusted counts\n",
    "plt.clf()  # Clear the current plot\n",
    "plt.hist(motoneuron_normalized_soma_diameters, density=False, weights=np.ones_like(motoneuron_normalized_soma_diameters) * (100 / len(motoneuron_normalized_soma_diameters)),\n",
    "         edgecolor='white', alpha=0.75, color='C2')\n",
    "plt.vlines(0,plt.ylim()[0],plt.ylim()[1],color='C1', label='Min soma diameter', linewidth=2)\n",
    "plt.vlines(1,plt.ylim()[0],plt.ylim()[1],color='C3', label='Max soma diameter', linewidth=2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Normalized motoneuron size\")\n",
    "plt.ylabel(\"Proportion (% of total nb of motoneurons)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(motoneuron_normalized_soma_diameters)\n",
    "xlabel(\"Motoneuron idx\")\n",
    "ylabel(\"Nomalized MN size\")\n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.title(\"Size of MNs according to index\")\n",
    "new_filename = f'MN_sizes_according_to_idx.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time constant (tau)\n",
    "tau_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "refractory_period_MN = np.zeros(nb_motoneurons_full_pool)\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    tau_motoneurons[mni] = tau_constant*(motoneuron_soma_diameters[mni]**((-1)*tau_exponent))\n",
    "    refractory_period_MN[mni] = lerp(refractory_period_smallest_MN,refractory_period_largest_MN, motoneuron_normalized_soma_diameters[mni])\n",
    "refractory_period_MN = refractory_period_MN * second\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(tau_motoneurons, color='C0', label='Time constant')\n",
    "plt.plot(refractory_period_MN*1000, color='C2', label='Refractory period')\n",
    "plt.title(\"Time constant (tau) and refractory period distribution of simulated MNs\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Motoneuron index (smallest MN is 0 ; largest MN is \"+str(nb_motoneurons_full_pool-1)+\")\")\n",
    "plt.vlines(target_force_level*nb_motoneurons_full_pool/100,plt.ylim()[0],plt.ylim()[1],color='black',linestyles='dashed',label=f'0-{target_force_level}% motoneurons')\n",
    "plt.ylabel(\"Time (ms)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Input resistance and input weight (normalized resistance)\n",
    "resistance_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "input_weight_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    resistance_motoneurons[mni] = resistance_constant*(motoneuron_soma_diameters[mni]**((-1)*resistance_exponent))\n",
    "    input_weight_motoneurons[mni] = resistance_motoneurons[mni]/resistance_motoneurons[0] \n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "ax1.plot(resistance_motoneurons, color='C1', label = 'Input resistance')\n",
    "ax1.set_ylabel(\"Resistance (ohms)\", color='C1')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(input_weight_motoneurons, color='C3', label = 'Input weight')\n",
    "ax2.set_ylabel(\"Input weight\", color='C3')\n",
    "ax2.set_ylim([0,1])\n",
    "plt.vlines(target_force_level*nb_motoneurons_full_pool/100,plt.ylim()[0],plt.ylim()[1],color='black',linestyles='dashed',label=f'0-{target_force_level}% motoneurons')\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "ax2.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "ax1.set_xlabel(\"Motoneuron index (smallest MN is 0 ; largest MN is \"+str(nb_motoneurons_full_pool-1)+\")\")\n",
    "plt.title(\"Resistance distribution of MNs\")\n",
    "plt.show()\n",
    "\n",
    "# Twitch force and duration and electromechanical delay (implemented as zeros before the kernel)\n",
    "twitch_force_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "electromechanical_delay_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "twitch_duration_motoneurons = np.zeros(nb_motoneurons_full_pool)\n",
    "twitch_convolution_window = [None] * nb_motoneurons_full_pool\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    twitch_force_motoneurons[mni] = lerp(twitch_force_range_small_MU,twitch_force_range_large_MU,motoneuron_normalized_soma_diameters[mni])\n",
    "    electromechanical_delay_motoneurons[mni] = 1/(axonal_conduction_velocity_constant*(motoneuron_soma_diameters[mni]**(axonal_conduction_velocity_exponent)))\n",
    "    twitch_duration_motoneurons[mni] = lerp(time_to_peak_twitch_force_range_small_MU,time_to_peak_twitch_force_range_large_MU,motoneuron_normalized_soma_diameters[mni])\n",
    "    # twitch_convolution_window[mni] = ((fsamp * twitch_duration_motoneurons[mni] * (1/2))**-1) * windows.hann(round(fsamp * twitch_duration_motoneurons[mni])) *  twitch_force_motoneurons[mni]\n",
    "    twitch_convolution_window[mni] = windows.hann(round(fsamp * twitch_duration_motoneurons[mni])) * twitch_force_motoneurons[mni]\n",
    "    # Extend the ramp down phase of the twitch so that it is five times the size of the ramp up phase (crude approximation based on Figure 1 of Raikova 2023. Full model explained in the paper https://www.sciencedirect.com/science/article/pii/S1050641123000330?via%3Dihub)\n",
    "    twitch_force_down_temp = twitch_convolution_window[mni][int(np.round(len(twitch_convolution_window[mni])/2)):len(twitch_convolution_window[mni])]\n",
    "    twitch_convolution_window[mni] = twitch_convolution_window[mni][:int(np.round(len(twitch_convolution_window[mni])/2))] # remove the down part (to be added in a few lines later)\n",
    "    original_indices = np.linspace(0, len(twitch_force_down_temp) - 1, num=len(twitch_force_down_temp)) # Create the indices of the original and new vectors\n",
    "    new_indices = np.linspace(0, len(twitch_force_down_temp) - 1, num = multiplication_of_twitch_force_down_time * len(twitch_force_down_temp) ) # Desired length of the new vector\n",
    "    twitch_force_down_stretched = np.interp(new_indices, original_indices, twitch_force_down_temp) # Perform linear interpolation\n",
    "    twitch_convolution_window[mni] = np.append(twitch_convolution_window[mni],twitch_force_down_stretched)\n",
    "    # insert zeros corresponding to electromechanical delay\n",
    "    delay_insamples = int(np.round(electromechanical_delay_motoneurons[mni]*fsamp))\n",
    "    twitch_convolution_window[mni] = np.append(np.zeros(delay_insamples), twitch_convolution_window[mni])\n",
    "    # Double the length of the vector with only zeros at the beginning, so that the convolution causes the force twitch to happen after each spike\n",
    "    twitch_convolution_window[mni] = np.append(np.zeros(len(twitch_convolution_window[mni])),twitch_convolution_window[mni])\n",
    "# figure of twitch force, twitch duration, electromechanical delay\n",
    "fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "ax1.plot(twitch_force_motoneurons, color='C1', label = 'Twitch force')\n",
    "ax1.set_ylabel(\"Twitch torque (milliNewton/meter)\", color='C1')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(twitch_duration_motoneurons*1e3, color='C2', label = 'Twitch duration')\n",
    "ax2.plot(electromechanical_delay_motoneurons*1e3, color='C4', label = 'Electromechanical delay')\n",
    "ax2.set_ylabel(\"Time (ms)\")\n",
    "plt.vlines(target_force_level*nb_motoneurons_full_pool/100,plt.ylim()[0],plt.ylim()[1],color='black',linestyles='dashed',label=f'0-{target_force_level}% motoneurons')\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "ax2.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "ax1.set_xlabel(\"Motoneuron index (smallest MN is 0 ; largest MN is \"+str(nb_motoneurons_full_pool-1)+\")\")\n",
    "plt.title(\"MNs force twitch properties\")\n",
    "new_filename = f'Twitch_force_properties.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Getting a smooth color blend from a given colormap\n",
    "colormap_temp = cm.get_cmap('plasma')\n",
    "# convolution windows\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    if mni == 0:\n",
    "        plt.plot(twitch_convolution_window[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 1, linewidth = 1.5, label = \"smallest simulated motor unit\")\n",
    "    elif mni == nb_motoneurons_full_pool-1:\n",
    "        plt.plot(twitch_convolution_window[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 1, linewidth = 1.5, label = \"largest simulated motor unit\")\n",
    "    elif mni == int(np.ceil(nb_motoneurons_full_pool*target_force_level/100)):\n",
    "        plt.plot(twitch_convolution_window[mni], color='black', alpha = 1, linewidth = 2.5, label=f'{target_force_level}% motoneurons')\n",
    "    else:\n",
    "        plt.plot(twitch_convolution_window[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 0.5, linewidth = 2)\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "ax.set_ylabel(\"Torque (milliNewton/meter)\")\n",
    "plt.legend()\n",
    "plt.title(\"Kernel for twitch torque convolution\")\n",
    "new_filename = f'Twitch_force_convolution_kernels.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Sanity check of the convolution process to obtain force\n",
    "binary_spike_test = np.zeros(1500)\n",
    "binary_spike_test[[100,200,700]] = 1\n",
    "conv_kernel_test = np.copy(twitch_convolution_window[0])\n",
    "conv_kernel_test = conv_kernel_test / max(conv_kernel_test)\n",
    "plt.figure()\n",
    "plt.plot(binary_spike_test,label=\"spike train\")\n",
    "test_conv = np.convolve(binary_spike_test, conv_kernel_test, mode='same')\n",
    "plt.plot(test_conv,label=\"force produced\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.title(\"Testing the convolution of the spike train with the twitch force kernel (visual sanity check)\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "def lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When rounding 2.7 for example, 70% to get 3 and 30% chance to get 2\n",
    "def probabilistic_round(number):\n",
    "    lower = int(number)  # The lower integer\n",
    "    upper = lower + 1    # The upper integer\n",
    "    decimal_part = number - lower\n",
    "    \n",
    "    return upper if random.random() < decimal_part else lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "\n",
    "# # Initialize network - groups of motoneurons and synapses\n",
    "# eqs_motoneuron = '''\n",
    "# dv/dt = ((I(t,i)*input_weight)-v)/tau: 1 (unless refractory)\n",
    "# tau : second\n",
    "# refractory_period : second\n",
    "# input_weight : 1\n",
    "# '''\n",
    "\n",
    "# same input for all motoneurons for initial optimization\n",
    "eqs_motoneuron = '''\n",
    "dv/dt = ((I(t)*input_weight)-v)/tau: 1 (unless refractory)\n",
    "tau : second\n",
    "refractory_period : second\n",
    "input_weight : 1\n",
    "'''\n",
    "\n",
    "# Groups of neurons\n",
    "motoneurons = NeuronGroup(nb_motoneurons_full_pool, eqs_motoneuron,\n",
    "                          threshold='v>voltage_thresh',\n",
    "                          reset='v=voltage_rest',\n",
    "                          refractory='refractory_period',\n",
    "                          method='exact')\n",
    "motoneurons.tau = tau_motoneurons*(1/1000)*second # convert to ms\n",
    "motoneurons.refractory_period = refractory_period_MN\n",
    "motoneurons.input_weight = input_weight_motoneurons\n",
    "\n",
    "# Display MN properties\n",
    "plt.plot(motoneurons.tau)\n",
    "plt.plot(motoneurons.input_weight)\n",
    "plt.plot(motoneurons.refractory_period)\n",
    "plt.xlabel(\"MN indx\")\n",
    "plt.title(\"MNs properties\")\n",
    "plt.vlines(target_force_level*nb_motoneurons_full_pool/100,plt.ylim()[0],plt.ylim()[1],color='black',linestyles='dashed',label=f'0-{target_force_level}% motoneurons')\n",
    "plt.legend([\"Time constant (seconds)\",\"Input weight (0-1 scaling factor)\",\"refractory period (seconds)\",f'0-{target_force_level}% motoneurons'])\n",
    "new_filename = f'Properties_MN.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Monitors\n",
    "monitor_state_motoneurons = StateMonitor(motoneurons, variables=True, record=True)\n",
    "monitor_spikes_motoneurons = SpikeMonitor(motoneurons, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET SPIKE TRAINS AND BINARY SPIKE TRAINS\n",
    "def Get_binary_spike_trains(spike_monitor, sim_duration):\n",
    "    # Define time bins\n",
    "    time_bins = np.arange(0, int(np.round((sim_duration*fsamp)))*second) * ms\n",
    "\n",
    "    # Retrieve spikes and get binary spike trains\n",
    "    spike_trains = []\n",
    "    for mni in range(nb_motoneurons_full_pool):\n",
    "        spike_trains.append(spike_monitor.spike_trains()[mni])\n",
    "    \n",
    "    # Initialize the binary spike train array\n",
    "    binary_spike_trains = {}\n",
    "    binary_spike_trains = np.zeros((nb_motoneurons_full_pool, len(time_bins)))\n",
    "    # Convert spike times to binary spike train\n",
    "    for neuron_idx in range(nb_motoneurons_full_pool):\n",
    "        spikes = spike_trains[neuron_idx]\n",
    "        spike_indices = np.searchsorted(time_bins, spikes)\n",
    "        binary_spike_trains[neuron_idx, spike_indices-1] = 1 #-1 because of offset due to 0-indexing\n",
    "    \n",
    "    return spike_trains, binary_spike_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVOLVE TO GET FORCE\n",
    "def Convolve_to_get_force(binary_spike_trains, corresponding_MN_idx, absolute_or_normalized):\n",
    "\n",
    "    force_per_MU = []\n",
    "    force_total = np.zeros(binary_spike_trains.shape[1])\n",
    "\n",
    "    if ndim(binary_spike_trains) > 1:\n",
    "        if shape(binary_spike_trains)[0] != len(corresponding_MN_idx):\n",
    "            print(\"Error = the number of MU indices provided do not match with the number of rows in the binary matrix\")\n",
    "        for mni in range(shape(binary_spike_trains)[0]):\n",
    "            # 'same' mode means the output length will be the same as the input length\n",
    "            if absolute_or_normalized == 'absolute':\n",
    "                temp_force = np.convolve(binary_spike_trains[mni,:], twitch_convolution_window[corresponding_MN_idx[mni]], mode='same')\n",
    "            elif absolute_or_normalized == 'normalized':\n",
    "                temp_force = np.convolve(binary_spike_trains[mni,:], twitch_convolution_window_normalized[corresponding_MN_idx[mni]], mode='same')\n",
    "            force_per_MU.append(temp_force)\n",
    "            # ax.plot(force_total, color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 0.5)\n",
    "            force_total = force_total + temp_force\n",
    "    else:\n",
    "        # if len(corresponding_MN_idx) != 1:        # len() doesn't work on a unique element\n",
    "        #     print(\"Error = the number of MU indices provided do not match with the number of rows in the binary matrix\")\n",
    "        if absolute_or_normalized == 'absolute':\n",
    "            temp_force = np.convolve(binary_spike_trains, twitch_convolution_window[corresponding_MN_idx[mni]], mode='same')\n",
    "        elif absolute_or_normalized == 'normalized':\n",
    "            temp_force = np.convolve(binary_spike_trains, twitch_convolution_window_normalized[corresponding_MN_idx[mni]], mode='same')\n",
    "        force_per_MU.append(temp_force)\n",
    "        force_total = force_total + temp_force\n",
    "    return force_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max tetanic force of the simulated pool => by sending a very very high input to all MNs and recording the resulting force\n",
    "# The force comes from the estimated peak torque values of individual motor units in the human tibialis anterior, so the low MVC values are not so unrealistic\n",
    "# Reset simulation\n",
    "start_scope() # Re-initialize the simulation\n",
    "\n",
    "# Set extremely (unrealistically high) input\n",
    "MVC_duration = 5 # in second\n",
    "synaptic_input_for_max_force = np.ones(MVC_duration*fsamp) * 10 # 10 is pretty good to get a mean firing rates of ~40pps (depending on the distribution of MN sizes) for the estimated MVC, which is physiologicaly plausible (https://pubmed.ncbi.nlm.nih.gov/6887053/)\n",
    "I = TimedArray(synaptic_input_for_max_force, dt=1*ms)\n",
    "# To estimate 100% MVC, if for example motor units are simulated up to 20% of largest motor units, resulting force will be multiplied by 1/0.2 = 5)\n",
    "nb_motoneurons_full_pool_to_simulate_for_MVC = nb_motoneurons_full_pool * (1/(max_normalized_boundary/100))\n",
    "\n",
    "eqs_motoneuron = '''\n",
    "dv/dt = ((I(t)*input_weight)-v)/tau: 1 (unless refractory)\n",
    "tau : second\n",
    "refractory_period : second\n",
    "input_weight : 1\n",
    "'''\n",
    "# Groups of neurons\n",
    "motoneurons = NeuronGroup(nb_motoneurons_full_pool, eqs_motoneuron,\n",
    "                        threshold='v>voltage_thresh',\n",
    "                        reset='v=voltage_rest',\n",
    "                        refractory='refractory_period',\n",
    "                        method='exact')\n",
    "motoneurons.tau = tau_motoneurons*(1/1000)*second # convert to ms\n",
    "motoneurons.refractory_period = refractory_period_MN\n",
    "motoneurons.input_weight = input_weight_motoneurons\n",
    "# Initialize voltage of MNs and Renshaw cells randomly\n",
    "motoneurons.v = rand() # uniform distribution between 0 and 1\n",
    "monitor_spikes_motoneurons = SpikeMonitor(motoneurons, record=True)\n",
    "# Run simulation\n",
    "run(MVC_duration * second)\n",
    "MVC_sim_samples = MVC_duration * fsamp\n",
    "# Get spike trains\n",
    "spike_trains, binary_spike_trains = Get_binary_spike_trains(monitor_spikes_motoneurons, MVC_duration)\n",
    "# Get force\n",
    "MVC_force = Convolve_to_get_force(binary_spike_trains,np.arange(nb_motoneurons_full_pool),'absolute')\n",
    "# Force per MU\n",
    "force_total = zeros(len(binary_spike_trains[0,:]))\n",
    "# Remove edges to get rid of artifacts (from convolution and/or synchronization of motor units)\n",
    "MVC_force = MVC_force[:MVC_sim_samples-fsamp]\n",
    "MVC_force = MVC_force[fsamp:]\n",
    "force_total = force_total[:MVC_sim_samples-fsamp]\n",
    "force_total = force_total[fsamp:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Getting a smooth color blend from a given colormap\n",
    "colormap_temp = cm.get_cmap('plasma')\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    # 'same' mode means the output length will be the same as the input length\n",
    "    temp_force = np.convolve(binary_spike_trains[mni,:], twitch_convolution_window[mni], mode='same')/1000\n",
    "    temp_force = temp_force[:MVC_sim_samples-fsamp]\n",
    "    temp_force = temp_force[fsamp:]\n",
    "    force_total += temp_force\n",
    "    ax.plot(force_total, color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 0.5)\n",
    "ax.plot(force_total, color='black', alpha = 1, linewidth = 2)\n",
    "plt.title(f\"Reconstructed torque (convolving spike train with twitch torque kernel)\")\n",
    "plt.ylabel(\"Torque (Newton/meter)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "new_filename = f'Max_force_for_simulated_MNs.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "\n",
    "### Get discharge characteristics of motoneurons\n",
    "mean_firing_rate = {}\n",
    "std_firing_rate = {}\n",
    "fig, axs = plt.subplots()\n",
    "firing_rates = []\n",
    "highest_ISIs = []\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    if len(spike_trains[mni]) <= 1:\n",
    "        highest_ISIs.append(MVC_duration*fsamp)\n",
    "    else:\n",
    "        highest_ISIs.append(max(diff(spike_trains[mni])))\n",
    "    firing_rate_temp = len(spike_trains[mni]) / MVC_duration\n",
    "    firing_rates.append(firing_rate_temp)\n",
    "# Convert to a numpy array for easier calculations\n",
    "firing_rates = np.array(firing_rates)\n",
    "# Calculate mean and standard deviation of the firing rates\n",
    "mean_firing_rate = np.mean(firing_rates)\n",
    "std_firing_rate = np.std(firing_rates)\n",
    "# Motoneurons' firing rates results\n",
    "axs.hist(firing_rates, edgecolor='white', alpha=0.75)\n",
    "axs.axvline(x = mean_firing_rate, linestyle='--', linewidth=2, label='Mean firing rate')\n",
    "axs.set_xlabel(\"Mean firing rate (pps)\")\n",
    "axs.set_ylabel(\"Motoneuron count count\")\n",
    "plt.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.suptitle(\"Histogram of motoneurons' firing rate - Very high excitatory input simulation (for MVC estimation)\")\n",
    " \n",
    "MVC_force = MVC_force/1000\n",
    "max_MVC_force = np.max(MVC_force)\n",
    "print(f'Estimated MVC (Newton/meter) = {max_MVC_force}')\n",
    "target_force_level_absolute_value = max_MVC_force * target_force_level/100\n",
    "print(f'Target torque level (Netwon/meter) = {target_force_level_absolute_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the twitch torque values of MUs in % of MVC\n",
    "total_peak_forces = np.sum((twitch_force_motoneurons/1000)/max_MVC_force)\n",
    "correcting_peak_force_value = 1 / total_peak_forces\n",
    "\n",
    "twitch_force_motoneurons_normalized = twitch_force_motoneurons/1000\n",
    "twitch_convolution_window_normalized = {}\n",
    "\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    twitch_force_motoneurons_normalized[mni] = (twitch_force_motoneurons_normalized[mni]/max_MVC_force)*correcting_peak_force_value\n",
    "    twitch_convolution_window_normalized[mni] = ((twitch_convolution_window[mni]/1000)/max_MVC_force)*correcting_peak_force_value*100 # *100 to express in % MVC\n",
    "\n",
    "# Getting a smooth color blend from a given colormap\n",
    "colormap_temp = cm.get_cmap('plasma')\n",
    "# convolution windows\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    if mni == 0:\n",
    "        plt.plot(twitch_convolution_window_normalized[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 1, linewidth = 1, label = \"smallest simulated motor unit\")\n",
    "    elif mni == nb_motoneurons_full_pool-1:\n",
    "        plt.plot(twitch_convolution_window_normalized[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 1, linewidth = 1, label = \"largest simulated motor unit\")\n",
    "    elif mni == int(np.ceil(nb_motoneurons_full_pool*target_force_level/100)):\n",
    "        plt.plot(twitch_convolution_window_normalized[mni], color='black', alpha = 1, linewidth = 2.5, label=f'{target_force_level}% motoneurons')\n",
    "    else:\n",
    "        plt.plot(twitch_convolution_window_normalized[mni], color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 0.5, linewidth = 2)\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "ax.set_ylabel(\"Torque (% of MVC)\")\n",
    "plt.legend()\n",
    "plt.title(\"Kernel for NORMALIZED twitch torque convolution\")\n",
    "new_filename = f'Twitch_force_convolution_kernels_normalized.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define force target\n",
    "if (target_type == 'plateau'):\n",
    "    print(\"Plateau force target\")\n",
    "    target_force = ones(int(duration_with_ignored_window * fsamp))*target_force_level\n",
    "elif (target_type == 'sinusoid'):\n",
    "    print(\"Sinusoidal force target\")\n",
    "    target_force = ones(int(duration_with_ignored_window * fsamp))*target_force_level\n",
    "    sinusoids_temp =  np.linspace(0, duration_with_ignored_window, int(duration_with_ignored_window*fsamp), endpoint=False)\n",
    "    sinusoids_temp = sinusoids_temp / second\n",
    "    sinusoids_temp = (target_force * 0.25) * np.sin(2 * np.pi * target_force_sin_freq * sinusoids_temp)\n",
    "    target_force = target_force + sinusoids_temp\n",
    "elif (target_type == 'trapezoid'):\n",
    "    print(\"Trapezoidal force target\")\n",
    "    target_force = np.zeros(int(window_beginning_ignore*fsamp))\n",
    "    ramp_up = linspace(0,target_force_level,ramp_duration*fsamp)\n",
    "    target_force = np.append(target_force,ramp_up)\n",
    "    plateau = ones(int(plateau_duration * fsamp))*target_force_level\n",
    "    target_force = np.append(target_force,plateau)\n",
    "    ramp_down = linspace(target_force_level,0,ramp_duration*fsamp)\n",
    "    target_force = np.append(target_force,ramp_down)\n",
    "    target_force = np.append(target_force,np.zeros(int(window_end_ignore*fsamp)))\n",
    "else:\n",
    "    print(\"Please select a valid target type type\")\n",
    "    sys.exit()\n",
    "\n",
    "plt.plot(target_force, color='black', alpha = 0.5, linewidth = 2)\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Target force (% MVC)\")\n",
    "plt.title(\"Target force\")\n",
    "new_filename = f'Target_force.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = linspace(0,duration_with_ignored_window/second,int(duration_with_ignored_window/second*fsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INHIBITORY INPUT\n",
    "Wind_s = 1/low_pass_filter_of_inhibitory_input  # hanning window duration.\n",
    "HanningW = 2 / round(fsamp * Wind_s) * windows.hann(round(fsamp * Wind_s))  # unitary area\n",
    "\n",
    "# Create inhibitory input\n",
    "inhib_input = {}\n",
    "if inhibitory_input_source == 'generate_synthetic_input':\n",
    "    for inhibiti in range(nb_inhibitory_input):\n",
    "        inhib_input[inhibiti] = []\n",
    "        temp_inhib = np.random.normal(0, 1, int(duration_with_ignored_window * fsamp))\n",
    "        temp_inhib[int(duration_with_ignored_window * fsamp)-int(np.round(window_beginning_ignore/1)):int(duration_with_ignored_window * fsamp)] = 0\n",
    "        temp_inhib[0:int(np.round(window_beginning_ignore/1))] = 0\n",
    "        temp_inhib = lowpass_filter(temp_inhib, low_pass_filter_of_inhibitory_input, fsamp)\n",
    "        # temp_inhib = filtfilt(HanningW, 1, temp_inhib * fsamp)\n",
    "        temp_inhib = temp_inhib - np.mean(temp_inhib)\n",
    "        temp_inhib = temp_inhib / np.std(temp_inhib)\n",
    "        temp_inhib = temp_inhib * inhibitory_input_std\n",
    "        temp_inhib = temp_inhib + inhibitory_input_mean\n",
    "        if prevent_inhibition_from_being_positive:\n",
    "            temp_inhib[temp_inhib > 0] = 0\n",
    "        inhib_input[inhibiti].append(temp_inhib)\n",
    "elif inhibitory_input_source == 'load_synthetic_input':\n",
    "    synthetic_signals_dataframe = pd.read_csv(inhibitory_input_sourcefile)\n",
    "    if inhibitory_input_sourcefile_fsamp != fsamp:\n",
    "        from scipy.interpolate import interp1d\n",
    "        # Calculate the time array for the original signal\n",
    "        loaded_signal_time = np.arange(len(synthetic_signals_dataframe)) / inhibitory_input_sourcefile_fsamp\n",
    "        # Calculate the number of samples in the resampled signal\n",
    "        number_of_samples = int(len(synthetic_signals_dataframe) * fsamp / inhibitory_input_sourcefile_fsamp)\n",
    "        # Calculate the time array for the resampled signal\n",
    "        resampled_time = np.linspace(loaded_signal_time[0], loaded_signal_time[-1], number_of_samples)\n",
    "    for inhibiti in range(nb_inhibitory_input):\n",
    "        inhib_input[inhibiti] = []\n",
    "        temp_inhib = synthetic_signals_dataframe[f'{inhibiti}'].values\n",
    "        if inhibitory_input_sourcefile_fsamp != fsamp:\n",
    "            # Create an interpolation function\n",
    "            resample_loaded_signal_function = interp1d(loaded_signal_time, temp_inhib, kind='linear')\n",
    "            temp_inhib = resample_loaded_signal_function(resampled_time)\n",
    "        temp_inhib = temp_inhib[:len(time)] # cut the signal for it to be the right size\n",
    "        temp_inhib = temp_inhib * inhibitory_input_std\n",
    "        temp_inhib = temp_inhib + inhibitory_input_mean\n",
    "        if prevent_inhibition_from_being_positive:\n",
    "            temp_inhib[temp_inhib > 0] = 0\n",
    "        inhib_input[inhibiti].append(temp_inhib)\n",
    "\n",
    "plt.figure()\n",
    "for inhibiti in range(nb_inhibitory_input):\n",
    "    plt.plot(np.transpose(inhib_input[inhibiti]), alpha = 0.5, label=f'Inhibitory input #{inhibiti}', color = 'C4')\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Inhibitory input(s)\")\n",
    "plt.legend()\n",
    "new_filename = f'Inhibitory_input_signal.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "if (inhibition_distribution == 'homogeneous'):\n",
    "    proportion_of_MN_affected_by_each_inhibitory_input = 100\n",
    "elif (inhibition_distribution == 'heterogeneous'):\n",
    "    proportion_of_MN_affected_by_each_inhibitory_input = proportion_of_MN_affected_by_each_inhibitory_input_original\n",
    "else:\n",
    "    print(\"Please select a valid inhibition distribution type ('homogeneous' or 'heterogeneous')\")\n",
    "    sys.exit()\n",
    "\n",
    "MN_inhibition_weights_curve = np.zeros(nb_motoneurons_full_pool)\n",
    "if (inhibition_weight_distribution == 'uniform'):\n",
    "    inhibition_exponent_weights = 0\n",
    "    inhibition_offset_weights = 0\n",
    "    inhibition_constant_weights = 1\n",
    "elif (inhibition_weight_distribution == 'exponential'):\n",
    "    inhibition_exponent_weights = inhibition_exponent_weights_original\n",
    "    inhibition_offset_weights = inhibition_offset_weights_original\n",
    "    inhibition_constant_weights = inhibition_constant_weights_original\n",
    "else:\n",
    "    print(\"Please select a valid inhibition weights distribution type ('uniform' or 'exponential')\")\n",
    "    sys.exit()\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    MN_inhibition_weights_curve[mni] = inhibition_constant_weights * (1-motoneuron_normalized_soma_diameters[mni])**inhibition_exponent_weights + inhibition_offset_weights\n",
    "    MN_inhibition_weights_curve[mni] = max(0,min(MN_inhibition_weights_curve[mni],1))\n",
    "\n",
    "plt.plot(MN_inhibition_weights_curve, color='C4')\n",
    "ylim([-0.1,1.1])\n",
    "ylabel(\"Inhibition weights\")\n",
    "xlabel(\"MN index\")\n",
    "\n",
    "\n",
    "# Distribute inhiitory input\n",
    "MN_receiving_inhibitory_input = {}\n",
    "for inhibiti in range(nb_inhibitory_input):\n",
    "    MN_receiving_inhibitory_input[inhibiti] = []\n",
    "    MN_receiving_inhibitory_input[inhibiti].append(np.random.choice(range(nb_motoneurons_full_pool),\n",
    "                                                                      int(np.round(nb_motoneurons_full_pool*(proportion_of_MN_affected_by_each_inhibitory_input/100))),\n",
    "                                                                      replace=False))\n",
    "    MN_receiving_inhibitory_input[inhibiti][0] = np.sort(MN_receiving_inhibitory_input[inhibiti][0])\n",
    "MN_inhibition_weights = {}\n",
    "for inhibiti in range(nb_inhibitory_input):\n",
    "    MN_inhibition_weights[inhibiti] = np.zeros(nb_motoneurons_full_pool)\n",
    "    for mni in MN_receiving_inhibitory_input[inhibiti][0]:\n",
    "        MN_inhibition_weights[inhibiti][mni] = MN_inhibition_weights_curve[mni]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,4))\n",
    "x_plot_mns = range(nb_motoneurons_full_pool)\n",
    "bottom_barplot = np.zeros(nb_motoneurons_full_pool)\n",
    "for inhibiti in range(nb_inhibitory_input):\n",
    "    vstack_inhibi_temp = MN_inhibition_weights[inhibiti]\n",
    "    ax.bar(x_plot_mns,\n",
    "        vstack_inhibi_temp,\n",
    "        bottom = bottom_barplot,\n",
    "        label = f\"inhibitory input #{inhibiti}\", color=\"C4\")\n",
    "    bottom_barplot += vstack_inhibi_temp\n",
    "ax.set_xlabel('Motoneurons')\n",
    "ax.set_ylabel('Inhibitory input weights')\n",
    "plt.suptitle(\"Distribution of inhibitory inputs according to INDICES\")\n",
    "plt.legend()\n",
    "new_filename = f'Inhibitory_input_distrib_relative_to_indices.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(motoneuron_normalized_soma_diameters,MN_inhibition_weights_curve, color='C4')\n",
    "ylim([-0.1,1.1])\n",
    "xlabel(\"Normalized MN size\")\n",
    "ylabel('Inhibitory input weights')\n",
    "plt.title(\"Distribution of inhibitory inputs according to SIZE\")\n",
    "new_filename = f'Inhibitory_input_distrib_relative_to_size.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitory_input_power_integral_0_5_hz = []\n",
    "for inhibiti in range(nb_inhibitory_input):\n",
    "    inhib_input_temp = np.copy(np.squeeze(np.array(inhib_input[inhibiti])))\n",
    "    # remove artifacts of low pass filter\n",
    "    inhib_input_temp[0:int(window_beginning_ignore*fsamp)] = inhibitory_input_mean\n",
    "    inhib_input_temp[len(time)-int(window_end_ignore*fsamp):len(time)] = inhibitory_input_mean\n",
    "    # Normalize\n",
    "    inhib_input_temp = ((inhib_input_temp - np.mean(inhib_input_temp)) / np.std(inhib_input_temp)) * inhibitory_input_std\n",
    "    N = len(inhib_input_temp)\n",
    "    yf = fft(inhib_input_temp)\n",
    "    xf = fftfreq(N, 1 / fsamp)\n",
    "    power_spectrum_temp = (np.abs(yf[:N//2])**2) / N\n",
    "    inhibitory_input_power_integral = np.sum(power_spectrum_temp)\n",
    "    if inhibiti == 0:\n",
    "        idx_corresponding_to_5hz = int(np.round((N/fsamp)*5))\n",
    "    power_spectrum_temp_0_5hz = power_spectrum_temp[:idx_corresponding_to_5hz]\n",
    "    inhibitory_input_power_integral_0_5_hz.append(np.sum(power_spectrum_temp_0_5hz))\n",
    "    plt.plot(xf[:N//2], power_spectrum_temp, color = 'C4', alpha = 1/nb_inhibitory_input)\n",
    "inhibitory_input_power_integral_0_5_hz_mean = np.mean(inhibitory_input_power_integral_0_5_hz)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Power spectrum of the inhibitory inputs\")\n",
    "plt.xlim([0,20])\n",
    "new_filename = f'Signal_inhibitory_input_power_spectrum.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate independent input to MNs\n",
    "plt.figure()\n",
    "independent_input_noise = randn(nb_motoneurons_full_pool,len(time)) # noise input, with mean zero and std 1 (default setting)\n",
    "# Plot the frequency domain independent noise signal\n",
    "# Apply low-pass filter to the Gaussian noise\n",
    "independent_input_noise_power_integral_0_5_hz = []\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    independent_input_noise[mni,:] = lowpass_filter(independent_input_noise[mni,:], low_pass_filter_of_independent_noise, fsamp,3)\n",
    "    # remove artifacts of low pass filter\n",
    "    independent_input_noise[mni,:][0:window_beginning_ignore*fsamp] = 0\n",
    "    independent_input_noise[mni,:][len(time)-(window_end_ignore*fsamp):len(time)] = 0\n",
    "    independent_input_noise[mni,:] = ((independent_input_noise[mni,:] - np.mean(independent_input_noise[mni,:])) / np.std(independent_input_noise[mni,:])) * independent_noise_amplitude\n",
    "    N = len(independent_input_noise[mni,:])\n",
    "    yf = fft(independent_input_noise[mni,:])\n",
    "    xf = fftfreq(N, 1 / fsamp)\n",
    "    power_spectrum_temp = (np.abs(yf[:N//2])**2) / N\n",
    "    independent_noise_power_integral = np.sum(power_spectrum_temp)\n",
    "    if mni == 0:\n",
    "        idx_corresponding_to_5hz = int(np.round((N/fsamp)*5))\n",
    "    power_spectrum_temp_0_5hz = power_spectrum_temp[:idx_corresponding_to_5hz]\n",
    "    independent_input_noise_power_integral_0_5_hz.append(np.sum(power_spectrum_temp_0_5hz))\n",
    "    plt.plot(xf[:N//2], power_spectrum_temp, color = 'C0', alpha = 1/nb_motoneurons_full_pool)\n",
    "independent_input_noise_power_integral_0_5_hz_mean = np.mean(independent_input_noise_power_integral_0_5_hz)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Power spectrum of the independent noise inputs\")\n",
    "plt.xlim([0,80])\n",
    "new_filename = f'Signal_independent_noise_power_spectrum.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input current + # Store initial control signal\n",
    "excit_I = ((target_force / target_force_level) * common_input_baseline)**(1/3) # **(1/2) or **(1/3) to make the relationship non linear and helping the optimizer converge when force is changing\n",
    "initial_excit_signal = excit_I.copy()\n",
    "samples_of_interest = list(range((window_beginning_ignore*fsamp),len(time)-(window_end_ignore*fsamp)))\n",
    "\n",
    "# Define the cost function\n",
    "def cost_function(output_force_var, target_force_var):\n",
    "    return np.sum(abs(output_force_var - target_force_var))\n",
    "\n",
    "# Gradient descent parameters\n",
    "learning_rate = 0.2\n",
    "# num_optimization_iterations = 10\n",
    "\n",
    "# Adam optimizer parameters\n",
    "initial_alpha = learning_rate  # Initial learning rate\n",
    "beta1 = 0.1 #0.9\n",
    "beta2 = 0.5 #0.999\n",
    "epsilon = 1e-8\n",
    "m = np.zeros_like(excit_I)\n",
    "v = np.zeros_like(excit_I)\n",
    "timestep = 0\n",
    "\n",
    "# Lists to store error and output force for plotting\n",
    "errors = []\n",
    "initial_output_force = None\n",
    "\n",
    "# Reset simulation\n",
    "start_scope() # Re-initialize the simulation\n",
    "\n",
    "optimized_excit_signal = np.copy(initial_excit_signal)\n",
    "best_cost = np.Inf\n",
    "best_iter_idx = 0\n",
    "# Optimization loop using Adam optimizer\n",
    "for iteration in range(num_optimization_iterations):\n",
    "    timestep += 1\n",
    "\n",
    "    # Low-pass filter the current excitatory input signal to prevent the \"learning/optimization\" towards an oscillating common input\n",
    "    # 1 hz cut-off\n",
    "    excit_I = lowpass_filter(excit_I, 1, fsamp)\n",
    "    # remove artifacts of low pass filter\n",
    "    excit_I[0:int(np.round(window_beginning_ignore*fsamp)*0.5)] = 0\n",
    "    excit_I[len(time)-int(np.round((window_end_ignore*fsamp)*0.5)):len(time)] = 0\n",
    "    # Prevent common input from going negative (it happens at the beginning of slopes)\n",
    "    excit_I[excit_I < 0] = 0\n",
    "\n",
    "    # Update input current in the neuron group\n",
    "    net_input_I = np.zeros((nb_motoneurons_full_pool,len(time)))\n",
    "    for mni in range(nb_motoneurons_full_pool):\n",
    "        net_input_I[mni,:] = excit_I\n",
    "        net_input_I[mni,:] += independent_input_noise[mni,:]\n",
    "        if (inhib_before_force_optimization == True):\n",
    "            for inhibiti in range(nb_inhibitory_input):\n",
    "                net_input_I[mni,:] += inhib_input[inhibiti][0]*MN_inhibition_weights[inhibiti][mni]\n",
    "    net_input_I = np.transpose(net_input_I)\n",
    "    I = TimedArray(net_input_I,dt=1*ms)\n",
    "\n",
    "    # same input for all motoneurons for initial optimization\n",
    "    eqs_motoneuron = '''\n",
    "    dv/dt = ((I(t,i)*input_weight)-v)/tau: 1 (unless refractory)\n",
    "    tau : second\n",
    "    refractory_period : second\n",
    "    input_weight : 1\n",
    "    '''\n",
    "    # Groups of neurons\n",
    "    motoneurons = NeuronGroup(nb_motoneurons_full_pool, eqs_motoneuron,\n",
    "                            threshold='v>voltage_thresh',\n",
    "                            reset='v=voltage_rest',\n",
    "                            refractory='refractory_period',\n",
    "                            method='exact')\n",
    "    motoneurons.tau = tau_motoneurons*(1/1000)*second # convert to ms\n",
    "    motoneurons.refractory_period = refractory_period_MN\n",
    "    motoneurons.input_weight = input_weight_motoneurons\n",
    "    # Initialize voltage of MNs and Renshaw cells randomly\n",
    "    motoneurons.v = rand() # uniform distribution between 0 and 1\n",
    "\n",
    "    monitor_spikes_motoneurons = SpikeMonitor(motoneurons, record=True)\n",
    "\n",
    "    # Run simulation\n",
    "    run(duration_with_ignored_window)\n",
    "\n",
    "    # Get spike trains\n",
    "    spike_trains, binary_spike_trains = Get_binary_spike_trains(monitor_spikes_motoneurons, duration_with_ignored_window)\n",
    "\n",
    "    # Get force\n",
    "    output_force = Convolve_to_get_force(binary_spike_trains,np.arange(nb_motoneurons_full_pool),'normalized')\n",
    "    # if low_pass_filter_force:\n",
    "        # output_force = lowpass_filter(output_force, low_pass_filter_of_force_cutoff, fsamp)\n",
    "    if iteration == 0:\n",
    "        initial_output_force = output_force\n",
    "    # During the learning phase, low-pass filtering the force helps the algorithm converge towards a better common input \"solution\"\n",
    "    output_force = lowpass_filter(output_force, 1, fsamp)\n",
    "\n",
    "    # Calculate cost\n",
    "    output_force_windowed = output_force[samples_of_interest]\n",
    "    target_force_windowed = target_force[samples_of_interest]\n",
    "    cost = cost_function(output_force_windowed, target_force_windowed)/len(samples_of_interest)\n",
    "    errors.append(cost)\n",
    "    print(f'Iteration {iteration + 1}, Cost: {np.round(cost*100)/100} (mean error in % of MVC)')\n",
    "    if cost < best_cost:\n",
    "        print(f'New best control signal')\n",
    "        best_cost = cost\n",
    "        optimized_excit_signal = np.copy(excit_I)\n",
    "        best_iter_idx = iteration\n",
    "\n",
    "    # Adjust learning rate inversely proportional to the error\n",
    "    alpha = min(cost*learning_rate*0.5,learning_rate)\n",
    "    # alpha = learning_rate\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = (output_force - target_force)\n",
    "\n",
    "    # Adam optimizer updates\n",
    "    m = beta1 * m + (1 - beta1) * gradients\n",
    "    v = beta2 * v + (1 - beta2) * (gradients ** 2)\n",
    "    m_hat = m / (1 - beta1 ** timestep)\n",
    "    v_hat = v / (1 - beta2 ** timestep)\n",
    "    excit_I -= alpha * m_hat / (np.sqrt(v_hat) + epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create common noise (fluctuation of the common input)\n",
    "if common_input_source  == 'generate_synthetic_input':\n",
    "    common_noise = randn(len(time)) # noise input, with mean zero and std 1 (default setting)\n",
    "    common_noise = lowpass_filter(common_noise, low_pass_filter_of_common_noise, fsamp)\n",
    "    # remove artifacts of low pass filter\n",
    "    common_noise[0:window_beginning_ignore*fsamp] = 0\n",
    "    common_noise[len(common_noise)-(window_end_ignore*fsamp):len(common_noise)] = 0\n",
    "elif common_input_source == 'load_synthetic_input':\n",
    "    synthetic_signals_dataframe = pd.read_csv(common_input_sourcefile)\n",
    "    common_noise = synthetic_signals_dataframe[f'{synthetic_signals_dataframe.shape[1]-1}'].values\n",
    "    if common_input_sourcefile_fsamp != fsamp:\n",
    "        from scipy.interpolate import interp1d\n",
    "        # Calculate the time array for the original signal\n",
    "        loaded_signal_time = np.arange(len(synthetic_signals_dataframe)) / common_input_sourcefile_fsamp\n",
    "        # Calculate the number of samples in the resampled signal\n",
    "        number_of_samples = int(len(synthetic_signals_dataframe) * fsamp / common_input_sourcefile_fsamp)\n",
    "        # Calculate the time array for the resampled signal\n",
    "        resampled_time = np.linspace(loaded_signal_time[0], loaded_signal_time[-1], number_of_samples)\n",
    "        # Create an interpolation function\n",
    "        resample_loaded_signal_function = interp1d(loaded_signal_time, common_noise, kind='linear')\n",
    "        common_noise = resample_loaded_signal_function(resampled_time)\n",
    "    common_noise = common_noise[:len(time)] # cut the signal for it to be the right size\n",
    "# Normalize\n",
    "common_noise = ((common_noise - np.mean(common_noise)) / np.std(common_noise)) * common_input_fluctuations_amplitude\n",
    "            \n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(common_noise, label=\"common noise\", color='C3')\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Common noise amplitude\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "N = len(common_noise)\n",
    "yf = fft(common_noise)\n",
    "xf = fftfreq(N, 1 / fsamp)\n",
    "power_spectrum_temp = (np.abs(yf[:N//2])**2) / N\n",
    "common_noise_power_integral = np.sum(power_spectrum_temp)\n",
    "idx_corresponding_to_5hz = int(np.round((N/fsamp)*5))\n",
    "power_spectrum_temp_0_5hz = power_spectrum_temp[:idx_corresponding_to_5hz]\n",
    "common_noise_power_intergal_0_5_hz = np.sum(power_spectrum_temp_0_5hz)\n",
    "plt.plot(xf[:N//2], power_spectrum_temp, color = 'C3', alpha = 1)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"Power spectrum of the common noise (fluctuations in common input)\")\n",
    "plt.xlim([0,10])\n",
    "new_filename = f'Common_noise_power_spectrum.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-run the simulation with the parameter ending up with the lowest cost, with a low-pass filter of the optimized signal + common noise\n",
    "# lowpass_filtered_optimized_excit_signal = lowpass_filter(optimized_excit_signal,1,fsamp) # 1hz low-pass filter\n",
    "# # remove artifacts of low pass filter\n",
    "# lowpass_filtered_optimized_excit_signal[0:int(np.round(window_beginning_ignore*fsamp)*0.5)] = 0\n",
    "# lowpass_filtered_optimized_excit_signal[len(time)-int(np.round((window_end_ignore*fsamp)*0.5)):len(time)] = 0\n",
    "# common_input = lowpass_filtered_optimized_excit_signal + common_noise\n",
    "\n",
    "common_input = optimized_excit_signal + common_noise\n",
    "\n",
    "net_input_I = np.zeros((nb_motoneurons_full_pool,len(time)))\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    net_input_I[mni,:] = common_input\n",
    "    net_input_I[mni,:] += independent_input_noise[mni,:]\n",
    "    for inhibiti in range(nb_inhibitory_input):     # Add the inhibition\n",
    "        net_input_I[mni,:] += inhib_input[inhibiti][0]*MN_inhibition_weights[inhibiti][mni]\n",
    "net_input_I = np.transpose(net_input_I)\n",
    "I = TimedArray(net_input_I,dt=1*ms)\n",
    "\n",
    "# same input for all motoneurons for initial optimization\n",
    "eqs_motoneuron = '''\n",
    "dv/dt = ((I(t,i)*input_weight)-v)/tau: 1 (unless refractory)\n",
    "tau : second\n",
    "refractory_period : second\n",
    "input_weight : 1\n",
    "'''\n",
    "# Groups of neurons\n",
    "motoneurons = NeuronGroup(nb_motoneurons_full_pool, eqs_motoneuron,\n",
    "                        threshold='v>voltage_thresh',\n",
    "                        reset='v=voltage_rest',\n",
    "                        refractory='refractory_period',\n",
    "                        method='exact')\n",
    "motoneurons.tau = tau_motoneurons*(1/1000)*second # convert to ms\n",
    "motoneurons.refractory_period = refractory_period_MN\n",
    "motoneurons.input_weight = input_weight_motoneurons\n",
    "# Initialize voltage of MNs and Renshaw cells randomly\n",
    "motoneurons.v = rand() # uniform distribution between 0 and 1\n",
    "\n",
    "monitor_spikes_motoneurons = SpikeMonitor(motoneurons, record=True)\n",
    "\n",
    "# Run simulation\n",
    "run(duration_with_ignored_window)\n",
    "\n",
    "# Get spike trains\n",
    "spike_trains, binary_spike_trains = Get_binary_spike_trains(monitor_spikes_motoneurons, duration_with_ignored_window)\n",
    "\n",
    "# Get force\n",
    "output_force = Convolve_to_get_force(binary_spike_trains,np.arange(nb_motoneurons_full_pool),'normalized')\n",
    "if low_pass_filter_force:\n",
    "    output_force = lowpass_filter(output_force, low_pass_filter_of_force_cutoff, fsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restrict window of analyzis\n",
    "samples_for_analyzis = []\n",
    "if target_type == 'trapezoid':\n",
    "    if analyzis_window == 'plateau':\n",
    "        samples_for_analyzis = np.arange((window_beginning_ignore+ramp_duration)*fsamp,len(time)-(window_end_ignore+ramp_duration)*fsamp)\n",
    "    else:\n",
    "        samples_for_analyzis = np.arange(window_beginning_ignore*fsamp,len(time)-window_end_ignore*fsamp)\n",
    "else:\n",
    "    samples_for_analyzis = np.arange(window_beginning_ignore*fsamp,len(time)-window_end_ignore*fsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error improvement\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost (mean error in % of MVC)')\n",
    "plt.ylim([0,np.ceil(max(errors))])\n",
    "plt.title('Cost Improvement Over Iterations')\n",
    "plt.grid(True)\n",
    "new_filename = f'Optimization_of_input_loss.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Plot target vs output force (initial and final)\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "plt.plot(target_force, label='Target Force')\n",
    "plt.plot(initial_output_force, label='Initial Output Force')\n",
    "if inhib_before_force_optimization:\n",
    "    plt.plot(output_force, label='Final Output Force (optimization of common excitatory input taking inhibition into account)')\n",
    "else:\n",
    "    plt.plot(output_force, label='Final Output Force (optimization of common excitatory ignoring inhibition = so force should be lower)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Force')\n",
    "plt.legend()\n",
    "plt.title('Force Output of Motor Neurons')\n",
    "plt.grid(True)\n",
    "new_filename = f'Optimized_input_resulting_force.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Plot control signal before and after learning\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "plt.plot(initial_excit_signal, label='Initial Control Signal')\n",
    "if inhib_before_force_optimization:\n",
    "    optimized_signal_label = 'Optimized Control Signal'\n",
    "    common_input_signal_label = 'Common input (optimized control signal + common noise)'\n",
    "else:\n",
    "    optimized_signal_label = 'Optimized Control Signal (ignoring inhibition which is applied later)'\n",
    "    common_input_signal_label = 'Common input (optimized control signal ignoring inhibition + common noise)'\n",
    "plt.plot(optimized_excit_signal, label=optimized_signal_label)\n",
    "plt.plot(common_input, label=common_input_signal_label)\n",
    "if nb_inhibitory_input >= 1:\n",
    "    for inhibiti in range(nb_inhibitory_input):\n",
    "        plt.plot(inhib_input[inhibiti][0], label=f'inhibitory input #{inhibiti+1}', color='C4', alpha = 1/nb_inhibitory_input)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Control Signal')\n",
    "plt.legend()\n",
    "# plt.ylim(0.5,2.5)\n",
    "plt.title('Control Signal Before and After Learning + common input')\n",
    "plt.grid(True)\n",
    "new_filename = f'Optimized_input_&_common_input.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean and std of common input during window of analyzis = {np.round(np.mean(common_input[samples_for_analyzis])*100)/100} +/- {np.round(np.std(common_input[samples_for_analyzis])*100)/100}')\n",
    "\n",
    "# Getting a smooth color blend from a given colormap\n",
    "colormap_temp = cm.get_cmap('plasma')\n",
    "\n",
    "# Raster plot of discharge times\n",
    "plt.figure(num=1,figsize=(20,10))\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    plt.scatter((spike_trains[mni]/second)*fsamp, np.ones(len(spike_trains[mni]))*mni, color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), linewidth = 0.5, alpha = 0.2)\n",
    "plt.vlines(samples_for_analyzis[0],plt.ylim()[0],plt.ylim()[1],color='black',label='Start of the analyzis window')\n",
    "plt.vlines(samples_for_analyzis[len(samples_for_analyzis)-1],plt.ylim()[0],plt.ylim()[1],color='black',label='End of the analyzis window')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Motoneuron index')\n",
    "plt.title(\"Raster plot of motoneuron spikes\")\n",
    "plt.legend()\n",
    "new_filename = f'Optimized_input_firings_raster_plot.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Force per MU\n",
    "force_per_MU = []\n",
    "force_total = zeros(len(binary_spike_trains[0,:]))\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    # 'same' mode means the output length will be the same as the input length\n",
    "    if len(spike_trains[mni]) >= 1: # at least one spike necessary\n",
    "        temp_force = np.convolve(binary_spike_trains[mni,:], twitch_convolution_window_normalized[mni], mode='same')\n",
    "        force_per_MU.append(temp_force)\n",
    "        ax.plot(force_total, color=colormap_temp(mni/(nb_motoneurons_full_pool-1)), alpha = 0.5, linewidth = 0.5)\n",
    "        force_total = force_total + temp_force\n",
    "if low_pass_filter_force:\n",
    "    ax.plot(output_force, color='black', alpha = 1, linewidth = 2, label = \"Total force (low-pass filtered)\")\n",
    "else:\n",
    "    ax.plot(force_total, color='black', alpha = 1, linewidth = 2, label = \"Total force\")\n",
    "plt.title(f\"Reconstructed force (convolving spike train with twitch force kernel)\")\n",
    "plt.ylabel(\"Force (% MVC)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.legend()\n",
    "new_filename = f'Optimized_input_cumulative_force_per_MU.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get discharge characteristics of motoneurons => only during window of analysis\n",
    "fig, axs = plt.subplots()\n",
    "# Retrieve spikes\n",
    "spike_trains = []\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    spike_trains.append(monitor_spikes_motoneurons.spike_trains()[mni])\n",
    "    # remove samples out of the analyzis window\n",
    "    spike_trains[mni] = spike_trains[mni]/second # convert into a simple numpy array first\n",
    "    spike_trains[mni] = spike_trains[mni][(spike_trains[mni] > (samples_for_analyzis[0]/fsamp)) & (spike_trains[mni] < (samples_for_analyzis[len(samples_for_analyzis)-1]/fsamp))]\n",
    "    # spike_trains[mni] = spike_trains[mni]*second # convert back into a Brian2 array with unit\n",
    "# Calculate the firing rate for each neuron\n",
    "firing_rates = []\n",
    "highest_ISIs = []\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    if len(spike_trains[mni]) <= 1:\n",
    "        highest_ISIs.append(len(samples_for_analyzis)/fsamp)\n",
    "    else:\n",
    "        highest_ISIs.append(max(diff(spike_trains[mni])))\n",
    "    firing_rate_temp = len(spike_trains[mni]) / (len(samples_for_analyzis)/fsamp)\n",
    "    firing_rates.append(firing_rate_temp)\n",
    "# Convert to a numpy array for easier calculations\n",
    "firing_rates = np.array(firing_rates)\n",
    "# Calculate mean and standard deviation of the firing rates\n",
    "mean_firing_rate = np.mean(firing_rates)\n",
    "std_firing_rate = np.std(firing_rates)\n",
    "# Motoneurons' firing rates results\n",
    "axs.hist(firing_rates, edgecolor='white', alpha=0.75)\n",
    "axs.axvline(x = mean_firing_rate, linestyle='--', linewidth=2, label='Mean firing rate')\n",
    "axs.set_xlabel(\"Mean firing rate (pps)\")\n",
    "axs.set_ylabel(\"Motoneuron count count\")\n",
    "plt.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.suptitle(\"Histogram of motoneurons' firing rate (all motoneurons, only during window of analyzis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SELECT ONLY VALID (continuous) MOTONEURONS\n",
    "discontinuous_MUs_idx = {}\n",
    "valid_MUs_idx = {}\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "# Index of discontinuous MNs (ISIs > 0.4)\n",
    "discontinuous_MUs_idx = [i for i, x in enumerate(highest_ISIs) if x > ISI_threshold_for_discontinuity]\n",
    "discontinuous_MUs_idx = append(discontinuous_MUs_idx,\n",
    "                            [i for i, x in enumerate(np.arange(nb_motoneurons_full_pool)) if len(spike_trains[x])<20]) # remove MUs with less than X spikes\n",
    "discontinuous_MUs_idx = unique(discontinuous_MUs_idx)\n",
    "\n",
    "valid_MUs_idx = [i for i, x in enumerate(arange(nb_motoneurons_full_pool)) if x not in discontinuous_MUs_idx]\n",
    "print(\"Number of invalid MUs = \", len(discontinuous_MUs_idx), \" out of \", nb_motoneurons_full_pool)\n",
    "axs.hist(highest_ISIs, edgecolor='white', alpha=0.5)\n",
    "axs.axvline(x = np.median(highest_ISIs), linestyle='--', linewidth=3, label='Mean highest ISI')\n",
    "axs.axvline(x = ISI_threshold_for_discontinuity, color = 'black', linestyle='-', linewidth=2, alpha = 0.5, label='Mean firing rate')\n",
    "axs.set_xlabel(\"Max ISI (s)\")\n",
    "axs.set_ylabel(\"Motoneuron count\")\n",
    "plt.tight_layout(rect=[0,0,1,0.92])\n",
    "plt.suptitle(\"Histogram of motoneurons' max ISI \\n (colored line is median ; black line is threshold)\")\n",
    "# new_filename = f'Hist_MN_ISIs.png'\n",
    "# save_file_path = os.path.join(new_directory, new_filename)\n",
    "# plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the softmax function\n",
    "def softmax_with_temperature(logits, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute the softmax of a list of logits with a temperature parameter.\n",
    "\n",
    "    Parameters:\n",
    "    logits (list or numpy array): The input logits.\n",
    "    temperature (float): The temperature parameter.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The softmax probabilities.\n",
    "    \"\"\"\n",
    "    # Convert logits to numpy array if they are not already\n",
    "    logits = np.array(logits)\n",
    "    \n",
    "    # Apply the temperature parameter\n",
    "    logits = logits / temperature\n",
    "    \n",
    "    # Compute the exponentials of the scaled logits\n",
    "    exp_logits = np.exp(logits - np.max(logits))  # Subtract max for numerical stability\n",
    "    \n",
    "    # Compute the softmax probabilities\n",
    "    softmax_probs = exp_logits / np.sum(exp_logits)\n",
    "    \n",
    "    return softmax_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A SUBSET OF MOTOR UNITS\n",
    "plot_title_text = 'sampling of motor units for analysis' \n",
    "\n",
    "if motor_unit_subsampling_probability_distribution == 'uniform':\n",
    "    sampling_probability_distribution = np.ones(shape(valid_MUs_idx))/len(valid_MUs_idx)\n",
    "else:\n",
    "    sampling_probability_distribution = np.copy(motoneuron_soma_diameters[valid_MUs_idx])\n",
    "    sampling_probability_distribution = softmax_with_temperature(sampling_probability_distribution, bias_towards_larger_motor_neurons_temperature)\n",
    "\n",
    "if subsample_MUs_for_analysis == False:\n",
    "    selected_motor_units = valid_MUs_idx.copy()\n",
    "    plot_title_text = plot_title_text + ' (all valid motor units selected)'\n",
    "    txt_for_legend = f'selected motor units (n={len(valid_MUs_idx)}=all continuously active motor units)'\n",
    "    plot_title_suffix = f' (all valid motor units)'\n",
    "else:\n",
    "    selected_motor_units = np.random.choice(valid_MUs_idx, size=nb_of_MUs_to_subsample, p=sampling_probability_distribution, replace=False)\n",
    "    plot_title_text = plot_title_text + f' (subset of {nb_of_MUs_to_subsample} motor units selected)'\n",
    "    txt_for_legend = f'selected motor units (n={nb_of_MUs_to_subsample})'\n",
    "    plot_title_suffix = f' (sampling of {nb_of_MUs_to_subsample} motor units)'\n",
    "# selected_motor_units_relative_to_valid_MUs = np.array([np.where(valid_MUs_idx == x)[0][0] for x in selected_motor_units])\n",
    "selected_motor_units_relative_to_valid_MUs = [valid_MUs_idx.index(x) for x in selected_motor_units]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(valid_MUs_idx,sampling_probability_distribution, label='probability of each valid (continuously firing) MU', color='C9', alpha=0.3)\n",
    "plt.bar(selected_motor_units,sampling_probability_distribution[selected_motor_units_relative_to_valid_MUs], label=txt_for_legend, color='C9')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Motor unit index\")\n",
    "plt.title(plot_title_text)\n",
    "\n",
    "new_filename = f'Valid_VS_sampled_motor_units_for_analyzis.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firing rate results - only selected MNs\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist(firing_rates[selected_motor_units], edgecolor='white', alpha=0.75)\n",
    "mean_firing_rate_valid = np.mean(firing_rates[selected_motor_units])\n",
    "std_firing_rate_valid = np.std(firing_rates[selected_motor_units])\n",
    "axs.axvline(x = mean_firing_rate_valid, linestyle='--', linewidth=2, label='Mean firing rate')\n",
    "axs.set_xlabel(\"Mean firing rate (pps)\")\n",
    "axs.set_ylabel(\"Motoneuron count count\")\n",
    "plt.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.suptitle(\"Histogram of motoneurons' firing rate\" + plot_title_suffix)\n",
    "new_filename = f'Hist_MN_Discharge_rates.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SMOOTHING SPIKE TRAINS\n",
    "\n",
    "Wind_s = 0.4  # hanning window duration. 0.4 for 2.5hz low-pass, 0.2 for 5hz low-pass\n",
    "HanningW = 2 / round(fsamp * Wind_s) * windows.hann(round(fsamp * Wind_s))  # unitary area\n",
    "\n",
    "# Filter all valid motor units\n",
    "smoothed_signal = []\n",
    "for mni in range(nb_motoneurons_full_pool):\n",
    "    if mni in valid_MUs_idx:\n",
    "        smoothed_signal.append(filtfilt(HanningW, 1, binary_spike_trains[mni, :] * fsamp))\n",
    "smoothed_signal = np.array(smoothed_signal)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "colormap_temp = cm.get_cmap('plasma') # Getting a smooth color blend from a given colormap\n",
    "if subsample_MUs_for_analysis == True:\n",
    "    for mni in range(len(valid_MUs_idx)):\n",
    "        ax.plot((smoothed_signal)[mni,:], color=colormap_temp(valid_MUs_idx[mni]/(nb_motoneurons_full_pool-1)), alpha = 0.3)\n",
    "# Remove non-valid motor units, and replot on top of the previous plot only the sampled motor units\n",
    "smoothed_signal = smoothed_signal[selected_motor_units_relative_to_valid_MUs,:]\n",
    "for mni in range(smoothed_signal.shape[0]):\n",
    "    ax.plot((smoothed_signal)[mni,:], color=colormap_temp(selected_motor_units[mni]/(nb_motoneurons_full_pool-1)), alpha = 1)\n",
    "\n",
    "plt.title(f\"Smoothed signals of only continuous MUs \\n (dark = small MNs ; light = large MNs) \\n (low opacity = valid but not selected ; opaque = selected motor units)\")\n",
    "plt.ylabel(\"Smoothed discharge rate (pps)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.vlines(samples_for_analyzis[0],plt.ylim()[0],plt.ylim()[1],color='black',label='Start of the analyzis window')\n",
    "plt.vlines(samples_for_analyzis[len(samples_for_analyzis)-1],plt.ylim()[0],plt.ylim()[1],color='black',label='End of the analyzis window')\n",
    "plt.legend()\n",
    "new_filename = f'Smoothed_discharge_rates_only_continuous_MUs.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "\n",
    "# restrict signal to window of analyzis, with only valid motor units\n",
    "smoothed_signal = smoothed_signal[:,samples_for_analyzis]\n",
    "# re-plot\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "for mni in range(smoothed_signal.shape[0]):\n",
    "    ax.plot(smoothed_signal[mni,:], color=colormap_temp(selected_motor_units[mni]/(nb_motoneurons_full_pool-1)))\n",
    "plt.title(f\"Smoothed signals only during window of analyzis\" + plot_title_suffix + \"\\n (dark = small MNs ; light = large MNs)\")\n",
    "plt.ylabel(\"Smoothed discharge rate (pps)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "new_filename = f'Smoothed_discharge_rates_only_continuous_MUs_window_of_analyzis.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# PCA\n",
    "smoothed_signal_normalized = np.copy(smoothed_signal)\n",
    "for mni in range(smoothed_signal.shape[0]):\n",
    "    smoothed_signal_normalized[mni] = smoothed_signal_normalized[mni]-np.mean(smoothed_signal_normalized[mni])\n",
    "    smoothed_signal_normalized[mni] = smoothed_signal_normalized[mni]/np.std(smoothed_signal_normalized[mni])\n",
    "\n",
    "# Displaye smoothed signals normalized (mean of 0, std of 1)\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "for mni in range(smoothed_signal.shape[0]):\n",
    "    ax.plot(smoothed_signal_normalized[mni,:], color=colormap_temp(selected_motor_units[mni]/(nb_motoneurons_full_pool-1)))\n",
    "plt.title(f\"Normalized smoothed signals of only continuous MUs, only during window of analyzis\"  + plot_title_suffix + \"\\n (dark = small MNs ; light = large MNs)\")\n",
    "plt.ylabel(\"Normalizd smoothed discharge rate (in std)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "new_filename = f'Smoothed_discharge_rates_ormalized_only_continuous_MUs_window_of_analyzis.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show(fig)\n",
    "\n",
    "nb_PCs_to_store = 5\n",
    "\n",
    "# Function to calculate R-squared for each time series with a given number of PCs\n",
    "def calculate_r_squared(data, pca, num_pcs):\n",
    "    # Transform the data using the selected number of PCs\n",
    "    transformed_data = pca.transform(data)\n",
    "    # Inverse transform to reconstruct the data\n",
    "    reconstructed_data = pca.inverse_transform(\n",
    "        np.hstack([transformed_data, np.zeros((data.shape[0], pca.n_components_ - num_pcs))])\n",
    "    )\n",
    "    # Calculate R-squared for each time series (motor unit)\n",
    "    r_squared_values = [r2_score(data[:, i], reconstructed_data[:, i]) for i in range(data.shape[1])]\n",
    "    return r_squared_values\n",
    "\n",
    "# Assume `smoothed_discharge_rates` is the variable holding     the data\n",
    "# Perform PCA\n",
    "nb_PCs = 10 # nb_motoneurons_full_pool\n",
    "pca = PCA(n_components=nb_PCs)\n",
    "pca_result = pca.fit_transform(transpose(smoothed_signal_normalized))\n",
    "\n",
    "# Initialize a DataFrame to store the R-squared values\n",
    "PCA_r_squared_df = pd.DataFrame(index=range(1, nb_PCs_to_store + 1), columns=range(smoothed_signal_normalized.shape[0])) # nb_PCs + 1\n",
    "# Calculate R-squared values for 1 to 2 PCs\n",
    "for num_pcs in range(1,nb_PCs_to_store+1): # From 1 to 2 PCs # nb_PCs + 1): \n",
    "    pca_temp = PCA(n_components=num_pcs)\n",
    "    pca_temp.fit(smoothed_signal_normalized.T)\n",
    "    r_squared_values = calculate_r_squared(smoothed_signal_normalized.T, pca_temp, num_pcs)\n",
    "    PCA_r_squared_df.loc[num_pcs] = r_squared_values\n",
    "\n",
    "# Display the explained variance ratio (proportion of variance explained by each PC)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "# Optionally, display the cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(0, nb_PCs + 1), append(0,explained_variance_ratio), alpha=0.5, align='center',\n",
    "        label='Individual explained variance')\n",
    "plt.plot(range(0, nb_PCs + 1), append(0,cumulative_explained_variance),\n",
    "         label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.title('Explained Variance by Principal Components' + plot_title_suffix)\n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "new_filename = f'Error_correction_PCA_VAF.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean R² of PC1+PC2 = {np.mean(PCA_r_squared_df.iloc[1])}')\n",
    "print(f'Cumulative VAF for PC1+PC2 = {cumulative_explained_variance[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate Fourier Analysis function - from NeuroSpec211 by Halliday - https://github.com/dmhalliday/NeuroSpec \n",
    "def sp2a2_R2(x, y, samp_rate, seg_pwr):\n",
    "\n",
    "    # Check number of input arguments\n",
    "    if x is None or y is None or samp_rate is None or seg_pwr is None:\n",
    "        raise ValueError('Not enough input arguments')\n",
    "\n",
    "    # Check for single column data\n",
    "    if len(x.shape) != 1:\n",
    "        raise ValueError('Input NOT single column: x')\n",
    "    if len(y.shape) != 1:\n",
    "        raise ValueError('Input NOT single column: y')\n",
    "\n",
    "    pts_tot = len(x)  # Determine size of data vector\n",
    "    if len(y) != pts_tot:  # Check that input vectors are equal length\n",
    "        raise ValueError('Unequal length data arrays')\n",
    "\n",
    "    if np.isscalar(samp_rate) is False:\n",
    "        raise ValueError('Non scalar value for: samp_rate')\n",
    "    if np.isscalar(seg_pwr) is False:\n",
    "        raise ValueError('Non scalar value for: seg_pwr')\n",
    "\n",
    "    # Segment for FFT\n",
    "    seg_size = 2 ** seg_pwr  # Segment length, T\n",
    "    seg_tot = pts_tot // seg_size  # No of segments, L\n",
    "    samp_tot = seg_tot * seg_size  # Record length, R = LT\n",
    "\n",
    "    x = x[:samp_tot].reshape((seg_size, seg_tot))  # Reshape x to T rows, L columns\n",
    "    y = y[:samp_tot].reshape((seg_size, seg_tot))  # Reshape y to T rows, L columns\n",
    "\n",
    "    # Create zero mean sequence for each segment\n",
    "    x -= x.mean(axis=0)\n",
    "    y -= y.mean(axis=0)\n",
    "\n",
    "    # FFT & average periodogram\n",
    "    dx = fft(x, axis=0)  # dFT across columns\n",
    "    dy = fft(y, axis=0)\n",
    "\n",
    "    psd_fac = 1 / (2 * np.pi * samp_tot)\n",
    "    fxx = psd_fac * np.sum(np.abs(dx) ** 2, axis=1)\n",
    "    fyy = psd_fac * np.sum(np.abs(dy) ** 2, axis=1)\n",
    "    fyx = psd_fac * np.sum(dy * np.conj(dx), axis=1)\n",
    "\n",
    "    # Coherence\n",
    "    chyx = np.zeros(seg_size)\n",
    "    chyx[1:] = np.abs(fyx[1:] ** 2) / (fxx[1:] * fyy[1:])\n",
    "\n",
    "    # Pre-whitening stage - generate MMSE filters\n",
    "    wx = np.zeros(seg_size)\n",
    "    wy = np.zeros(seg_size)\n",
    "    wx[1:] = 1.0 / np.sqrt(fxx[1:])\n",
    "    wy[1:] = 1.0 / np.sqrt(fyy[1:])\n",
    "\n",
    "    # Apply MMSE pre-whitening filters\n",
    "    dxw = dx * wx[:, np.newaxis]\n",
    "    dyw = dy * wy[:, np.newaxis]\n",
    "\n",
    "    # Re-calculate spectra using pre-whitened processes\n",
    "    fxxw = psd_fac * np.sum(np.abs(dxw) ** 2, axis=1)\n",
    "    fyyw = psd_fac * np.sum(np.abs(dyw) ** 2, axis=1)\n",
    "    fyxw = psd_fac * np.sum(dyw * np.conj(dxw), axis=1)\n",
    "\n",
    "    chyxw = np.abs(fyxw) ** 2\n",
    "    rhoyx = np.real(ifft(fyxw))\n",
    "\n",
    "    # R2 in frequency domain\n",
    "    R2_ch = np.sum(chyx) / seg_size\n",
    "    R2_chw = np.sum(chyxw) / seg_size\n",
    "\n",
    "    # Estimate R2 in time domain and separate components\n",
    "    R2_rho = np.sum(rhoyx ** 2)\n",
    "    R2_rho_0 = rhoyx[0] ** 2\n",
    "    R2_rho_p = np.sum(rhoyx[1:seg_size // 2] ** 2)\n",
    "    R2_rho_n = np.sum(rhoyx[seg_size // 2:] ** 2)\n",
    "\n",
    "    # Decompose rho into three components by lag\n",
    "    rhoyx_3 = np.zeros((seg_size, 3))\n",
    "    rhoyx_3[0, 0] = rhoyx[0]\n",
    "    rhoyx_3[1:seg_size // 2, 1] = rhoyx[1:seg_size // 2]\n",
    "    rhoyx_3[seg_size // 2:, 2] = rhoyx[seg_size // 2:]\n",
    "\n",
    "    # Switch back to frequency domain for f' estimates\n",
    "    f_prime = fft(rhoyx_3, axis=0)\n",
    "    f_prime2 = np.abs(f_prime) ** 2\n",
    "\n",
    "    # Scale to get relative contributions\n",
    "    f_prime2_fac = np.sum(f_prime2, axis=1)\n",
    "    R2_weight = f_prime2 / f_prime2_fac[:, np.newaxis]\n",
    "\n",
    "    R2_fprime_0 = np.sum(f_prime2[:, 0]) / seg_size\n",
    "    R2_fprime_p = np.sum(f_prime2[:, 1]) / seg_size\n",
    "    R2_fprime_n = np.sum(f_prime2[:, 2]) / seg_size\n",
    "\n",
    "    # Construct output matrix f\n",
    "    f = np.zeros((seg_size // 2, 12))\n",
    "    f_index = np.arange(1, seg_size // 2 + 1)\n",
    "    deltaf = samp_rate / seg_size\n",
    "\n",
    "    f[:, 0] = (f_index - 1) * deltaf  # Column 1 - frequencies in Hz\n",
    "    f[:, 1] = np.log10(fxx[f_index])  # Column 2 - Log spectrum ch 1, x\n",
    "    f[:, 2] = np.log10(fyy[f_index])  # Column 3 - Log spectrum ch 2, y\n",
    "    f[:, 3] = chyx[f_index]           # Column 4 - Coherence\n",
    "    f[:, 4] = np.angle(fyx[f_index])  # Column 5 - Phase\n",
    "    f[:, 5] = fxxw[f_index]           # Column 6 - MMSE whitened spectra process x\n",
    "    f[:, 6] = fyyw[f_index]           # Column 7 - MMSE whitened spectra process y\n",
    "    f[:, 7] = chyxw[f_index]          # Column 8 - Coherence between whitened processes\n",
    "    f[:, 8] = np.angle(fyxw[f_index]) # Column 9 - Phase between whitened processes\n",
    "    f[:, 9] = R2_weight[f_index, 0] * chyxw[f_index]  # Column 10 - Zero lag coherence component\n",
    "    f[:, 10] = R2_weight[f_index, 1] * chyxw[f_index] # Column 11 - Forward coherence component\n",
    "    f[:, 11] = R2_weight[f_index, 2] * chyxw[f_index] # Column 12 - Reverse coherence component\n",
    "\n",
    "    # Construct time domain matrix t\n",
    "    deltat = 1000.0 / samp_rate  # dt in msec\n",
    "    t = np.zeros((seg_size, 3))\n",
    "    t[:, 0] = (np.arange(1, seg_size + 1) - seg_size // 2 - 1) * deltat  # Lag range\n",
    "    t[np.r_[seg_size // 2:seg_size, 0:seg_size // 2], 1] = 2 * np.pi * np.real(ifft(fyx))  # Cumulant density\n",
    "    t[np.r_[seg_size // 2:seg_size, 0:seg_size // 2], 2] = rhoyx  # rhoyx\n",
    "\n",
    "    # Estimate variance of cumulant density and rho estimates\n",
    "    var_fac = 4 * np.pi ** 2 / (seg_size * samp_tot)\n",
    "    q_var = var_fac * 2 * np.sum(fxx[:seg_size // 2 + 1] * fyy[:seg_size // 2 + 1])\n",
    "    rho_var = 1 / samp_tot\n",
    "\n",
    "    cl = {\n",
    "        'type': 0,\n",
    "        'seg_size': seg_size,\n",
    "        'seg_tot': seg_tot,\n",
    "        'seg_tot_var': seg_tot,\n",
    "        'samp_tot': samp_tot,\n",
    "        'samp_rate': samp_rate,\n",
    "        'dt': deltat,\n",
    "        'df': deltaf,\n",
    "        'f_c95': 0.8512 * np.sqrt(1 / seg_tot),\n",
    "        'ch_c95': 1 - 0.05 ** (1 / (seg_tot - 1)),\n",
    "        'q_c95': 1.96 * np.sqrt(q_var),\n",
    "        'rho_c95': 1.96 * np.sqrt(rho_var),\n",
    "        'col_R20': 10,\n",
    "        'col_R2p': 11,\n",
    "        'col_R2n': 12,\n",
    "        'col_rho': 3,\n",
    "        'R2': R2_rho,\n",
    "        'R2_0': R2_rho_0,\n",
    "        'R2_p': R2_rho_p,\n",
    "        'R2_n': R2_rho_n,\n",
    "        'R2_ch': R2_ch,\n",
    "        'R2_chw': R2_chw,\n",
    "        'R2_fprime_0': R2_fprime_0,\n",
    "        'R2_fprime_p': R2_fprime_p,\n",
    "        'R2_fprime_n': R2_fprime_n,\n",
    "        'N1': 0,\n",
    "        'N2': 0,\n",
    "        'P1': 0,\n",
    "        'P2': 0,\n",
    "        'opt_str': '',\n",
    "        'what': ''\n",
    "    }\n",
    "\n",
    "    # print(f'Segments: {seg_tot}, Segment length: {seg_size/samp_rate} sec, Resolution: {cl[\"df\"]} Hz.')\n",
    "    # print(f'  R2 (0, p, n): {cl[\"R2\"]} ({cl[\"R2_0\"]}, {cl[\"R2_p\"]}, {cl[\"R2_n\"]}).')\n",
    "\n",
    "    return f, t, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import csd, detrend\n",
    "\n",
    "windowCOH = 1 # in seconds\n",
    "frequencies_per_FFT_window = 10\n",
    "indexes_of_windows_below_5hz = np.arange(0,5*frequencies_per_FFT_window)\n",
    "\n",
    "# From groups of 2 up to half of the motor neurons\n",
    "shuffled_idx_list = list.copy(list(selected_motor_units)) # initialize list of indices to be shuffled iteratively\n",
    "window_analyzis_begin = int(samples_for_analyzis[0])\n",
    "window_analyzis_end = int(samples_for_analyzis[len(samples_for_analyzis)-1])\n",
    "seg_pwr = 10 # segment length (for coherence analyzis), specificied as a power of 2. 2^10 is ~1s for a fsamp of 1000\n",
    "\n",
    "max_or_mean_0_5hz_COH = 'max'\n",
    "\n",
    "COH_calc_group_size_nb = int(floor(len(selected_motor_units)/2)-1)\n",
    "# COH_calc_max_iteration_nb_per_group_size = 1000 # More iteration for smaller group sizes, because the value obtained is very dependent upon the exact neurons selected, especially when only a few MNs are used to create the CST\n",
    "COH_0_5hz_per_group = []\n",
    "COH_mean_0_5hz = np.zeros(COH_calc_group_size_nb)\n",
    "COH_pooled_per_group_size = []\n",
    "\n",
    "colors_plots = plt.cm.winter(np.linspace(0, 1, COH_calc_group_size_nb))\n",
    "plt.figure(figsize=(10,8))\n",
    "for group_sizi in range(COH_calc_group_size_nb):\n",
    "    coherence_temp = []\n",
    "    COH_calc_iteration_nb_per_group_size_temp = int(np.max([np.round(COH_calc_max_iteration_nb_per_group_size/(group_sizi+1)),1]))\n",
    "    COH_0_5hz_per_group.append([])\n",
    "    print(f'Iterating for groups of {group_sizi+1} motoneurons (out of a max group size of {COH_calc_group_size_nb}) - {COH_calc_iteration_nb_per_group_size_temp} iterations')\n",
    "    for group_iteri in range(COH_calc_iteration_nb_per_group_size_temp):\n",
    "        random.shuffle(shuffled_idx_list)\n",
    "        idx_cst1 = np.copy(shuffled_idx_list[0:group_sizi+1])\n",
    "        cst1 = sum(binary_spike_trains[idx_cst1,window_analyzis_begin:window_analyzis_end],axis=0)\n",
    "        idx_cst2 = np.copy(shuffled_idx_list[len(shuffled_idx_list)-(group_sizi+1):len(shuffled_idx_list)])\n",
    "        cst2 = sum(binary_spike_trains[idx_cst2,window_analyzis_begin:window_analyzis_end],axis=0)\n",
    "\n",
    "        # Compute intra-group coherence for group 1\n",
    "        f, COH_intragroup_X = csd(detrend(cst1), detrend(cst1), window=windows.hann(round(windowCOH * fsamp)), noverlap=0, nfft=frequencies_per_FFT_window * fsamp, fs=fsamp)\n",
    "        # Compute intra-group coherence for group 2\n",
    "        f, COH_intragroup_Y = csd(detrend(cst2), detrend(cst2), window=windows.hann(round(windowCOH * fsamp)), noverlap=0, nfft=frequencies_per_FFT_window * fsamp, fs=fsamp)\n",
    "        # Compute inter-group coherence\n",
    "        f, COH_intergroup = csd(detrend(cst1), detrend(cst2), window=windows.hann(round(windowCOH * fsamp)), noverlap=0, nfft=frequencies_per_FFT_window * fsamp, fs=fsamp)\n",
    "\n",
    "        coherence_temp.append( (np.abs(COH_intergroup) ** 2) / (COH_intragroup_X * COH_intragroup_Y) ) # Welch's method of coherence calculation\n",
    "        if max_or_mean_0_5hz_COH == 'mean':\n",
    "            # COH_0_5hz_per_group[group_sizi,group_iteri] = np.nanmean(coherence_temp[group_iteri][indexes_of_windows_below_5hz])\n",
    "            COH_0_5hz_per_group[group_sizi].append(np.nanmean(coherence_temp[group_iteri][indexes_of_windows_below_5hz]))\n",
    "        elif max_or_mean_0_5hz_COH == 'max':\n",
    "            # COH_0_5hz_per_group[group_sizi,group_iteri] = np.nanmax(coherence_temp[group_iteri][indexes_of_windows_below_5hz])\n",
    "            COH_0_5hz_per_group[group_sizi].append(np.nanmax(coherence_temp[group_iteri][indexes_of_windows_below_5hz]))\n",
    "\n",
    "        # plt.scatter(group_sizi,COH_0_5hz_per_group[group_sizi,group_iteri],s=30,color=colors_plots[group_sizi],alpha=min(3/COH_calc_iteration_nb_per_group_size,1))\n",
    "        plt.scatter(group_sizi,COH_0_5hz_per_group[group_sizi][group_iteri],s=30,color=colors_plots[group_sizi],alpha=min(np.sqrt(1/COH_calc_iteration_nb_per_group_size_temp),1))\n",
    "    COH_pooled_per_group_size.append( np.nanmean(coherence_temp, axis=0) )\n",
    "    # COH_mean_0_5hz[group_sizi] = np.nanmean(COH_0_5hz_per_group[group_sizi,:],axis=0)\n",
    "    COH_mean_0_5hz[group_sizi] = np.nanmean(COH_0_5hz_per_group[group_sizi],axis=0)\n",
    "\n",
    "plt.plot(COH_mean_0_5hz, linewidth=3, color='red', alpha=0.5, label=f\"Mean of [max 0-5hz coherence for CSTs of X spike trains]\")\n",
    "plt.xlabel('Number of MNs in the CSTs')\n",
    "plt.ylabel('Mean coherence in the 0-5hz bandwidth')\n",
    "plt.title(\"Increase in coherence in the 0-5hz bandwidth (Y) as the number of CSTS' MNs (X) increase\" + plot_title_suffix)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "new_filename = f'PCI_curve_of_0-5hz_coh.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for group_sizi in range(COH_calc_group_size_nb):\n",
    "    plt.plot(COH_pooled_per_group_size[group_sizi], color=colors_plots[group_sizi], alpha = 0.5, linewidth = 2)\n",
    "plt.xlim(0,20*frequencies_per_FFT_window)\n",
    "plt.xticks(ticks=plt.xticks()[0], labels=[str(int(x / frequencies_per_FFT_window)) for x in plt.xticks()[0]])\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Mean coherence\" + plot_title_suffix)\n",
    "new_filename = f'Coherence_curve.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean square error function definition\n",
    "def rmse(predicted, true):\n",
    "    # Root mean square\n",
    "    # return np.sqrt(np.mean((true - predicted) ** 2))\n",
    "    # Mean square\n",
    "    return np.mean((true - predicted) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit, least_squares\n",
    "\n",
    "# Define the model - implementation from Negro et al 2016 https://physoc.onlinelibrary.wiley.com/doi/epdf/10.1113/JP271748 \n",
    "def PCI_model(n, A, B):\n",
    "    return abs(n**2 * A)**2 / ((n*B) + ((n**2)*A))**2\n",
    "# Define the residuals function\n",
    "def residuals(params, x, y):\n",
    "    A, B = params\n",
    "    return y - PCI_model(x, A, B)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "n = np.arange(1,COH_mean_0_5hz.shape[0]+1)\n",
    "# Negro 2016 equation:\n",
    "# Mean COH in a given frequency band: Eqn 4 = abs(n**2 * A)**2 / ((n*B) + ((n**2)*A))**2\n",
    "#   - n = number of neurons in the CST\n",
    "#   - A = power of the common synaptic input (in the given frequency band), multipled by the absolute square of the susceptibility\n",
    "#   - A = abs(X(f))**2 * Ss(f)\n",
    "#       => X(f) is the response function (susceptibility) of the motor neuron [POOl of motor neurons in our case] to the stimulus and Ss(f) the power spectrum of the stimulus\n",
    "#   - B = (power of the?) response of the pool with independent synaptic input\n",
    "#   - B = Sn(f)\n",
    "#       => Sn(f)is the power spectrum of the output spike train [CST of spike train in our case] when it is driven by independent synaptic input only\n",
    "#   - proportion of common input (PCI) = estimate of gamma (common voltage fluctuation of membrane) = sqrt(A/(B+A)) = proportion of the common synaptic input with respect to the total synaptic input received by the motor neurons [total input can be inferred from motor pool output, because it the output is a function of both the common and independent input]\n",
    "#       => They say just sqrt(A/B) in the paper, but this can result in a proportion (PCI) > 1 which shouldn't be possible, and I get results fitting very closely the theoritical values when computing sqrt(A_fit / (B_fit + A_fit))\n",
    "#   - The ratio can be estimated by an experimental measure of the mean coherence in the given frequency range for varying n (number of motor neuron spike trains used in the calculation (Negro & Farina, 2012)) using eqn (4)\n",
    "#   - Using a least-square curve fitting of the estimated values of coherence for CSTs with different numbers of motor neurons, the parameters A and B of eqn (4) can be estimated.\n",
    "\n",
    "# params, covariance = curve_fit(PCI_model, xdata = n, ydata = COH_mean_0_5hz) # older version, still works well\n",
    "initial_guess = [1, 1] # Initial guess for the parameters from which to optimize using least squares\n",
    "least_square_optim_results = least_squares(residuals, initial_guess, loss='soft_l1', f_scale=0.1, args=(n, COH_mean_0_5hz)) # default loss function is 'linear' but 'soft_l1' is a bit more robust to fluctuations\n",
    "# Extract parameters\n",
    "A_fit, B_fit = least_square_optim_results.x\n",
    "PCI_estimated = np.sqrt(A_fit/(B_fit+A_fit))\n",
    "fitted_PCI_curve = PCI_model(n, A_fit, B_fit)\n",
    "\n",
    "# Get ratio of common excitatory input to independent input = Grond-truth PCI\n",
    "# = power spectrum integral of common input in the 0-5hz range over power spectrum integral of independent input in the same range\n",
    "# Ignoring inhibitory input = hard to calculate, so no ground truth when simulating inhibition\n",
    "PCI_ground_truth_without_inhib = np.sqrt(common_noise_power_intergal_0_5_hz / (common_noise_power_intergal_0_5_hz + independent_input_noise_power_integral_0_5_hz_mean))\n",
    "\n",
    "plt.plot(COH_mean_0_5hz, color='C0',linewidth=2.5, alpha = 0.5, label='ground truth curve')\n",
    "plt.plot(fitted_PCI_curve, color='blue',linewidth=2, alpha = 0.5, linestyle='dashed',label='fitted curve')\n",
    "plt.xlabel('Number of MNs in the CSTs')\n",
    "plt.ylabel('Mean coherence in the 0-5hz bandwidth')\n",
    "plt.title(f\"Increase in coherence in the 0-5hz bandwidth (Y) as the number of CSTS' MNs (X) increase => Ground-truth VS fitted data\" + plot_title_suffix + f\"\\n Estimated PCI (gamma) = {np.round(PCI_estimated*1000)/1000} \\n Ground-truth PCI (ratio of common input 0-5hz integral of power spectrum VS idem common+independent input) = {np.round(PCI_ground_truth_without_inhib*1000)/10}%, ignoring inhibition \\n\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "new_filename = f'PCI_fitted_vs_true_curve.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SIMON'S INSPIRED VERSION - Implementation from Negro et al 2016 https://physoc.onlinelibrary.wiley.com/doi/epdf/10.1113/JP271748 \n",
    "# plt.figure(figsize=(12,8))\n",
    "# n = np.arange(1,COH_mean_0_5hz.shape[0]+1)\n",
    "# # Negro 2016 equation:\n",
    "# # Mean COH in a given frequency band: Eqn 4 = (abs(n**2 * A)**2) / ((n*B) + (((n**2)*A))**2)\n",
    "# #   - n = number of neurons in the CST\n",
    "# #   - A = power of the common synaptic input (in the given frequency band), multipled by the absolute square of the susceptibility (which is 1 when considering the 0-5hz bandwidth I think)\n",
    "# #   - B = response of the pool with independent synaptic input (of the same bandwidth). Assumed to be 1 for the 0-5hz bandwidth.\n",
    "# #       (k in the fitting below correspond to sqrt(B), since)\n",
    "# #   #   #\n",
    "# #   - proportion of common input (PCI) = estimate of gamma (common voltage fluctuation of membrane) = sqrt(A/B) = proportion of the common synaptic input with respect to the total synaptic input received by the motor neurons\n",
    "# #   - The ratio can be estimated by an experimental measure of the mean coherence in the given frequency range for varying n (number of motor neuron spike trains used in the calculation (Negro & Farina, 2012)) using eqn (4)\n",
    "# #   - Using a least-square curve fitting of the estimated values of coherence for CSTs with different numbers of motor neurons, the parameters A and B of eqn (4) can be estimated.\n",
    "# nb_gammas_to_try = int(1e3) # Correspond to B\n",
    "# gamma_tmp = np.linspace(0.1,1e2,nb_gammas_to_try)\n",
    "# gamma_fit_error = []\n",
    "# for k in gamma_tmp:\n",
    "#     c = n**4 / (n / k**2 + n**2)**2\n",
    "#     plt.plot(c, color='C0',linewidth=1, alpha = min(5/nb_gammas_to_try,1))\n",
    "#     gamma_fit_error.append(rmse(c,COH_mean_0_5hz))\n",
    "# idx_with_min_error = gamma_fit_error.index(min(gamma_fit_error))\n",
    "# gamma = np.sqrt(gamma_tmp[idx_with_min_error]**2 / (gamma_tmp[idx_with_min_error]**2 +1))\n",
    "# fitted_PCI_curve = n**4 / ( n / gamma_tmp[idx_with_min_error]**2 + n**2 )**2\n",
    "# # fitted_PCI_curve = n**4 / ( n / gamma**2 + n**2 )**2\n",
    "\n",
    "# # Get ratio of common excitatory input to independent input = Grond-truth PCI\n",
    "# # = power spectrum integral of common input in the 0-5hz range over power spectrum integral of independent input in the same range\n",
    "# # Ignoring inhibitory input = hard to calculate, so no ground truth when simulating inhibition\n",
    "# PCI_ground_truth_without_inhib = np.sqrt(common_noise_power_intergal_0_5_hz / (common_noise_power_intergal_0_5_hz + independent_input_noise_power_integral_0_5_hz_mean))\n",
    "\n",
    "# plt.plot(COH_mean_0_5hz, color='C0',linewidth=2.5, alpha = 0.5, label='ground truth curve')\n",
    "# plt.plot(fitted_PCI_curve, color='blue',linewidth=2, alpha = 0.5, linestyle='dashed',label='fitted curve')\n",
    "# plt.xlabel('Number of MNs in the CSTs')\n",
    "# plt.ylabel('Mean coherence in the 0-5hz bandwidth')\n",
    "# plt.title(f\"Increase in coherence in the 0-5hz bandwidth (Y) as the number of CSTS' MNs (X) increase => Ground-truth VS fitted data \\n Estimated PCI (gamma) = {np.round(gamma*1000)/1000} \\n Ground-truth PCI (ratio of common input variance VS independent input variance) = {np.round(PCI_ground_truth_without_inhib*1000)/10}%, ignoring inhibition \\n\")\n",
    "# plt.ylim(0,1)\n",
    "# plt.legend()\n",
    "# new_filename = f'PCI_fitted_vs_true_curve.png'\n",
    "# save_file_path = os.path.join(new_directory, new_filename)\n",
    "# plt.savefig(save_file_path)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recruitment threshold and discharge rates of motor units = only if chosing the \"trapezoid\" force target (because allows for gradual recruitment of motor units)\n",
    "if target_type == 'trapezoid':\n",
    "    MN_mean_firing_rates = np.copy(firing_rates) # all motoneurons by index, regardless of whether they are valid or not\n",
    "    # Discharge rates duging the window of analyzis (the plateau section of the trapezoid)\n",
    "    MN_recruitment_thresholds = np.full(firing_rates.shape, np.nan) # in % MVC\n",
    "    spike_trains_full, binary_spike_trains_full = Get_binary_spike_trains(monitor_spikes_motoneurons, duration_with_ignored_window)\n",
    "    for mni in valid_MUs_idx:\n",
    "        # RT as force during the median time of the first 3 firings\n",
    "        temp_RT = (spike_trains_full[mni]/second)*fsamp\n",
    "        temp_RT = np.median(temp_RT[0:2])\n",
    "        MN_recruitment_thresholds[mni] = output_force[int(np.round(temp_RT))]\n",
    "\n",
    "MN_recruitment_thresholds_only_selected_idx = np.copy(MN_recruitment_thresholds)\n",
    "MN_recruitment_thresholds_only_selected_idx = MN_recruitment_thresholds_only_selected_idx[selected_motor_units].reshape(-1, 1)\n",
    "MN_mean_firing_rates_only_selected_idx = np.copy(MN_mean_firing_rates)\n",
    "MN_mean_firing_rates_only_selected_idx = MN_mean_firing_rates[selected_motor_units].reshape(-1, 1)\n",
    "\n",
    "# histogram of recruitment thresholds\n",
    "plt.figure()\n",
    "plt.hist(MN_recruitment_thresholds_only_selected_idx, density=True,\n",
    "         edgecolor='white', alpha=0.75, color='C1')\n",
    "plt.xlim(0,target_force_level*1.1)\n",
    "ylabel(\"Proportion\")\n",
    "xlabel(\"Recruitment threshold (% MVC)\")\n",
    "title(\"Histogram of recruitment tresholds\" + plot_title_suffix)\n",
    "new_filename = f'RT_hsitogram.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "true_false_continuously_firing_MUs = np.zeros(nb_motoneurons_full_pool)\n",
    "true_false_continuously_firing_MUs[valid_MUs_idx] = 1\n",
    "true_false_sampled_motor_unit = np.zeros(nb_motoneurons_full_pool)\n",
    "true_false_sampled_motor_unit[selected_motor_units] = 1\n",
    "\n",
    "if nb_inhibitory_input == 0:\n",
    "    MN_inhibition_weights = [np.zeros(shape(MN_inhibition_weights))]\n",
    "\n",
    "sampling_probability_dsitribution_to_save = np.zeros(nb_motoneurons_full_pool)\n",
    "if subsample_MUs_for_analysis == True:\n",
    "    sampling_probability_dsitribution_to_save[valid_MUs_idx] = sampling_probability_distribution\n",
    "else:\n",
    "    sampling_probability_dsitribution_to_save[valid_MUs_idx] = 1\n",
    "\n",
    "# Save recruitment thresholds and firing rates\n",
    "RT_mean_DR_dataframe = pd.DataFrame({\n",
    "    'MU_idx': np.arange(nb_motoneurons_full_pool),\n",
    "    'Continusouly_firing': true_false_continuously_firing_MUs,\n",
    "    'Sampled_for_analyzis': true_false_sampled_motor_unit,\n",
    "    'Recruitment_threshold': MN_recruitment_thresholds,\n",
    "    'Mean_firing_rate': MN_mean_firing_rates,\n",
    "    'Soma_size': motoneuron_soma_diameters,\n",
    "    'Probability_of_being_sampled': sampling_probability_dsitribution_to_save,\n",
    "    'Inhibition_weight_(1st_inhibitory_input)': MN_inhibition_weights[0]\n",
    "})\n",
    "new_filename = f'Individual_MUs_results.csv'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "RT_mean_DR_dataframe.to_csv(save_file_path, index=False)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "# Fit the model\n",
    "model.fit(MN_recruitment_thresholds_only_selected_idx, MN_mean_firing_rates_only_selected_idx)\n",
    "# Get the slope (coefficient)\n",
    "slope = model.coef_[0]\n",
    "# Predict the Y values using the fitted model\n",
    "Y_pred = model.predict(MN_recruitment_thresholds_only_selected_idx)\n",
    "# Calculate R squared\n",
    "r_squared = r2_score(MN_mean_firing_rates_only_selected_idx, Y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(MN_recruitment_thresholds_only_selected_idx,MN_mean_firing_rates_only_selected_idx,s=70,alpha=0.35,color='C1')\n",
    "plt.plot(MN_recruitment_thresholds_only_selected_idx, Y_pred,color='C3',alpha=0.5, linewidth=3, label=f'Linear regression (slope = {np.round(slope[0]*100)/100}; R² = {np.round(r_squared*100)/100})')\n",
    "plt.xlabel('Recruitment threshold (% MVC)')\n",
    "plt.ylabel(\"Mean firing rate on the plateau (pps)\")\n",
    "plt.ylim(0,np.ceil(max(MN_mean_firing_rates)/10)*10)\n",
    "plt.title(\"Recruitment threshold to mean discharge rate relationship\" + plot_title_suffix)\n",
    "plt.legend()\n",
    "plt.xlim(0,target_force_level*1.1)\n",
    "new_filename = f'RT_to_mean_DR_relationship.png'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "plt.savefig(save_file_path)\n",
    "plt.show()\n",
    "\n",
    "mean_inhib_weights_of_active_MUs = 0\n",
    "if nb_inhibitory_input > 0:\n",
    "    for inhibiti in range(nb_inhibitory_input):\n",
    "        mean_inhib_weights_of_active_MUs += np.mean(MN_inhibition_weights[inhibiti][selected_motor_units])\n",
    "    mean_inhib_weights_of_active_MUs = mean_inhib_weights_of_active_MUs / nb_inhibitory_input\n",
    "\n",
    "### Force output\n",
    "force_output_window_of_analyzis = output_force[samples_for_analyzis]\n",
    "force_output_error_window_of_analyzis = np.abs(output_force[samples_for_analyzis] - target_force[samples_for_analyzis])\n",
    "mean_force_error_window_of_analyzis = np.mean(force_output_error_window_of_analyzis)\n",
    "mean_force_output_window_of_analyzis = np.mean(force_output_window_of_analyzis)\n",
    "std_force_output_window_of_analyzis = np.std(force_output_window_of_analyzis)\n",
    "\n",
    "\n",
    "### Main results\n",
    "main_results_dataframe = pd.DataFrame({\n",
    "    'Simulation_name': sim_name,\n",
    "    'Window_of_analyzis_duration': (window_analyzis_end-window_analyzis_begin)/fsamp,\n",
    "    'Ground_truth_PCI_ignoring_inhibition': [PCI_ground_truth_without_inhib], #[] to make sure at least the first value is an array\n",
    "    'PCSI_estimation': PCI_estimated,\n",
    "    'VAF_for_PC1': cumulative_explained_variance[0],\n",
    "    'Slope_of_RT_mean_DR_relationship': slope[0],\n",
    "    'Nb_of_continously_active_MUs': len(valid_MUs_idx),\n",
    "    'Nb_of_sampled_MUs_for_analyzis': len(selected_motor_units),\n",
    "    'Mean_DR': np.mean(MN_mean_firing_rates_only_selected_idx),\n",
    "    'std_DR': np.std(MN_mean_firing_rates_only_selected_idx),\n",
    "    'Mean_RT': np.mean(MN_recruitment_thresholds_only_selected_idx),\n",
    "    'std_RT': np.std(MN_recruitment_thresholds_only_selected_idx),\n",
    "    '0-5hz power of common input': common_noise_power_intergal_0_5_hz,\n",
    "    '0-5hz power of inhibition': inhibitory_input_power_integral_0_5_hz_mean,\n",
    "    '0-5hz power of independent noise': independent_input_noise_power_integral_0_5_hz_mean,\n",
    "    'Mean weight of inhibition': mean_inhib_weights_of_active_MUs,\n",
    "    'Mean torque': mean_force_output_window_of_analyzis,\n",
    "    'Mean torque error': mean_force_error_window_of_analyzis,\n",
    "    'Torque variability (torque std)': std_force_output_window_of_analyzis\n",
    "    })\n",
    "new_filename = f'Main_results.csv'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "main_results_dataframe.to_csv(save_file_path, index=False)\n",
    "\n",
    "### Cumulative Explained Variance\n",
    "VAF_cumsum_dataframe = pd.DataFrame({\n",
    "    'PC': np.arange(len(cumulative_explained_variance))+1,\n",
    "    'Cumulative_VAF': cumulative_explained_variance\n",
    "    })\n",
    "new_filename = f'Cumulative_VAF_PCA.csv'\n",
    "save_file_path = os.path.join(new_directory, new_filename)\n",
    "VAF_cumsum_dataframe.to_csv(save_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
